# src/utils/config_synchronizer.py
"""
é…ç½®åŒæ­¥å·¥å…· - ç¢ºä¿æ‰€æœ‰æ¨¡çµ„ä½¿ç”¨çµ±ä¸€é…ç½®
è‡ªå‹•åŒæ­¥ config.py èˆ‡ enhanced_transformer_config.json
"""

import json
import sys
from pathlib import Path
from typing import Dict, Any

# ç¢ºä¿èƒ½å°å…¥é…ç½®
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

try:
    from src.common.config import *
except ImportError:
    print("âŒ ç„¡æ³•å°å…¥ config.pyï¼Œè«‹æª¢æŸ¥è·¯å¾‘")
    sys.exit(1)


def sync_transformer_config():
    """åŒæ­¥ Transformer é…ç½®åˆ° JSON æ–‡ä»¶"""
    
    config_path = Path(__file__).parent.parent.parent / "configs" / "enhanced_transformer_config.json"
    
    # å¾ config.py æ§‹å»ºé…ç½®
    unified_config = {
        "model": {
            "type": "EnhancedUniversalTradingTransformer",
            "model_dim": TRANSFORMER_MODEL_DIM,
            "num_layers": TRANSFORMER_NUM_LAYERS,
            "num_heads": TRANSFORMER_NUM_HEADS,
            "ffn_dim": TRANSFORMER_FFN_DIM,
            "dropout_rate": TRANSFORMER_DROPOUT_RATE,
            "timesteps": TIMESTEPS,
            "output_dim_per_symbol": TRANSFORMER_OUTPUT_DIM_PER_SYMBOL,
            "use_multi_scale": ENHANCED_TRANSFORMER_USE_MULTI_SCALE,
            "use_cross_time_fusion": ENHANCED_TRANSFORMER_USE_CROSS_TIME_FUSION,
            "multi_scale_kernels": ENHANCED_TRANSFORMER_MULTI_SCALE_KERNELS,
            "time_scales": ENHANCED_TRANSFORMER_TIME_SCALES
        },
        "training": {
            "total_timesteps": TRAINER_DEFAULT_TOTAL_TIMESTEPS,
            "learning_rate": 0.0001,
            "batch_size": 32,
            "buffer_size": 200000,
            "gradient_steps": 2,
            "train_freq": 4,
            "target_update_interval": 1000,
            "save_freq": TRAINER_SAVE_FREQ_STEPS,
            "eval_freq": TRAINER_EVAL_FREQ_STEPS,
            "n_eval_episodes": TRAINER_N_EVAL_EPISODES
        },
        "progressive_learning": {
            "enabled": True,
            "stage_advancement_episodes": 50,
            "reward_threshold_basic": -0.1,
            "reward_threshold_intermediate": 0.05,
            "reward_threshold_advanced": 0.15
        },
        "meta_learning": {
            "enabled": True,
            "adaptation_rate": 0.01,
            "memory_size": 1000,
            "update_frequency": 100
        },
        "quantum_strategies": {
            "enabled": True,
            "num_strategies": 20,
            "strategy_update_frequency": 500
        },
        "early_stopping": {
            "patience": EARLY_STOPPING_PATIENCE,
            "min_delta_percent": EARLY_STOPPING_MIN_DELTA_PERCENT,
            "min_evals": EARLY_STOPPING_MIN_EVALS
        },
        "device": {
            "device": str(DEVICE),
            "use_amp": USE_AMP
        },
        "data": {
            "max_symbols": MAX_SYMBOLS_ALLOWED,
            "default_symbols": DEFAULT_SYMBOLS,
            "granularity": GRANULARITY
        }
    }
    
    # ä¿å­˜é…ç½®
    config_path.parent.mkdir(exist_ok=True)
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(unified_config, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… é…ç½®å·²åŒæ­¥è‡³: {config_path}")
    
    # é©—è­‰ç¶­åº¦ä¸€è‡´æ€§
    model_dim = unified_config['model']['model_dim']
    num_heads = unified_config['model']['num_heads']
    
    if model_dim % num_heads != 0:
        print(f"âŒ ç¶­åº¦ä¸åŒ¹é…: model_dim({model_dim}) % num_heads({num_heads}) = {model_dim % num_heads}")
        return False
    else:
        print(f"âœ… ç¶­åº¦æª¢æŸ¥é€šé: model_dim({model_dim}) / num_heads({num_heads}) = {model_dim // num_heads}")
        return True


def validate_config_consistency():
    """é©—è­‰é…ç½®ä¸€è‡´æ€§"""
    
    print("ğŸ” æª¢æŸ¥é…ç½®ä¸€è‡´æ€§...")
    
    issues = []
    
    # æª¢æŸ¥åŸºæœ¬ç¶­åº¦
    if TRANSFORMER_MODEL_DIM % TRANSFORMER_NUM_HEADS != 0:
        issues.append(f"TRANSFORMER_MODEL_DIM({TRANSFORMER_MODEL_DIM}) å¿…é ˆè¢« TRANSFORMER_NUM_HEADS({TRANSFORMER_NUM_HEADS}) æ•´é™¤")
    
    # æª¢æŸ¥ FFN ç¶­åº¦
    expected_ffn = TRANSFORMER_MODEL_DIM * 4
    if TRANSFORMER_FFN_DIM != expected_ffn:
        issues.append(f"TRANSFORMER_FFN_DIM({TRANSFORMER_FFN_DIM}) æ‡‰ç‚º MODEL_DIM * 4 = {expected_ffn}")
    
    # æª¢æŸ¥è¨­å‚™é…ç½®
    if not hasattr(sys.modules.get('torch', None), 'cuda'):
        issues.append("PyTorch æœªæ­£ç¢ºå®‰è£æˆ–å°å…¥")
    
    # æª¢æŸ¥è·¯å¾‘
    required_dirs = ['data', 'logs', 'weights', 'configs']
    base_path = Path(__file__).parent.parent.parent
    
    for dir_name in required_dirs:
        dir_path = base_path / dir_name
        if not dir_path.exists():
            issues.append(f"ç›®éŒ„ä¸å­˜åœ¨: {dir_path}")
    
    if issues:
        print("âŒ ç™¼ç¾å•é¡Œ:")
        for i, issue in enumerate(issues, 1):
            print(f"  {i}. {issue}")
        return False
    else:
        print("âœ… æ‰€æœ‰é…ç½®æª¢æŸ¥é€šé")
        return True


def auto_create_directories():
    """è‡ªå‹•å‰µå»ºå¿…è¦ç›®éŒ„"""
    
    base_path = Path(__file__).parent.parent.parent
    required_dirs = [
        'data',
        'logs', 
        'weights',
        'configs',
        'reports',
        'data/database',
        'data/mmap_s5_universal',
        'logs/tensorboard'
    ]
    
    created_dirs = []
    for dir_name in required_dirs:
        dir_path = base_path / dir_name
        if not dir_path.exists():
            dir_path.mkdir(parents=True, exist_ok=True)
            created_dirs.append(str(dir_path))
    
    if created_dirs:
        print(f"âœ… å·²å‰µå»ºç›®éŒ„: {len(created_dirs)} å€‹")
        for dir_path in created_dirs:
            print(f"  - {dir_path}")
    else:
        print("â„¹ï¸ æ‰€æœ‰å¿…è¦ç›®éŒ„å·²å­˜åœ¨")


def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ”§ OANDA äº¤æ˜“æ©Ÿå™¨äººé…ç½®åŒæ­¥å·¥å…·")
    print("="*50)
    
    # 1. å‰µå»ºå¿…è¦ç›®éŒ„
    print("\n1. å‰µå»ºå¿…è¦ç›®éŒ„...")
    auto_create_directories()
    
    # 2. é©—è­‰é…ç½®ä¸€è‡´æ€§
    print("\n2. é©—è­‰é…ç½®ä¸€è‡´æ€§...")
    config_valid = validate_config_consistency()
    
    # 3. åŒæ­¥é…ç½®æ–‡ä»¶
    print("\n3. åŒæ­¥é…ç½®æ–‡ä»¶...")
    sync_success = sync_transformer_config()
    
    # 4. æœ€çµ‚ç‹€æ…‹
    print("\n" + "="*50)
    if config_valid and sync_success:
        print("ğŸ‰ é…ç½®åŒæ­¥å®Œæˆï¼ç³»çµ±å¯ä»¥é‹è¡Œ")
        print("\næ¥ä¸‹ä¾†å¯ä»¥åŸ·è¡Œ:")
        print("  1. python å•Ÿå‹•å®Œæ•´ç›£æ§ç³»çµ±.bat")
        print("  2. æˆ–ç›´æ¥é‹è¡Œ Streamlit: streamlit run streamlit_app_complete.py")
        return True
    else:
        print("âŒ é…ç½®åŒæ­¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤è¨Šæ¯")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
