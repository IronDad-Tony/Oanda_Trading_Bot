# src/utils/config_validator_fixed.py
"""
é…ç½®çµ±ä¸€æ€§é©—è­‰å’Œä¿®å¾©å·¥å…·
æª¢æŸ¥ç³»çµ±å„æ¨¡çµ„é–“é…ç½®çš„ä¸€è‡´æ€§ï¼Œä¸¦æä¾›è‡ªå‹•ä¿®å¾©å»ºè­°

ä¸»è¦åŠŸèƒ½ï¼š
1. é…ç½®ä¸€è‡´æ€§æª¢æŸ¥
2. ç¶­åº¦åŒ¹é…é©—è­‰  
3. è‡ªå‹•ä¿®å¾©å»ºè­°
4. é…ç½®ç‰ˆæœ¬ç®¡ç†
"""

import os
import json
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
import torch
import numpy as np

try:
    from oanda_trading_bot.training_system.common.logger_setup import logger
    from oanda_trading_bot.training_system.common.config import *
except ImportError:
    logger = logging.getLogger(__name__)


@dataclass
class ConfigIssue:
    """é…ç½®å•é¡Œæè¿°"""
    level: str  # "error", "warning", "info"
    category: str  # "dimension", "path", "value", "compatibility"
    module: str
    issue: str
    current_value: Any
    expected_value: Any = None
    fix_suggestion: str = ""


@dataclass
class ValidationReport:
    """é©—è­‰å ±å‘Š"""
    timestamp: str
    total_checks: int
    passed_checks: int
    issues: List[ConfigIssue]
    critical_errors: int
    warnings: int
    overall_status: str  # "passed", "warnings", "failed"


class ConfigValidator:
    """é…ç½®é©—è­‰å™¨"""
    
    def __init__(self):
        self.project_root = Path(__file__).resolve().parent.parent.parent
        self.config_files = self._discover_config_files()
        self.issues = []
        
    def _discover_config_files(self) -> List[Path]:
        """ç™¼ç¾æ‰€æœ‰é…ç½®ç›¸é—œæ–‡ä»¶"""
        config_patterns = [
            "src/common/config.py",
            "configs/*.json",
            "src/environment/*config*.py", 
            "src/models/*config*.py",
            "src/agent/*config*.py"
        ]
        
        files = []
        for pattern in config_patterns:
            if "*" in pattern:
                parts = pattern.split("*")
                base_dir = self.project_root / parts[0]
                if base_dir.exists():
                    for file in base_dir.rglob(f"*{parts[1]}*{parts[2] if len(parts) > 2 else ''}"):
                        files.append(file)
            else:
                file_path = self.project_root / pattern
                if file_path.exists():
                    files.append(file_path)
        
        return files
    
    def validate_all(self) -> ValidationReport:
        """åŸ·è¡Œå…¨é¢é…ç½®é©—è­‰"""
        logger.info("é–‹å§‹é…ç½®ä¸€è‡´æ€§é©—è­‰...")
        
        self.issues = []
        checks = [
            self._check_dimension_consistency,
            self._check_path_validity,
            self._check_transformer_config,
            self._check_quantum_strategy_config,
            self._check_progressive_learning_config,
            self._check_device_compatibility,
            self._check_data_consistency,
            self._check_training_parameters
        ]
        
        total_checks = len(checks)
        passed_checks = 0
        
        for check in checks:
            try:
                if check():
                    passed_checks += 1
                logger.info(f"âœ“ å®Œæˆæª¢æŸ¥: {check.__name__}")
            except Exception as e:
                self._add_issue("error", "system", "ConfigValidator", 
                              f"æª¢æŸ¥ {check.__name__} å¤±æ•—: {str(e)}")
                logger.error(f"âœ— æª¢æŸ¥å¤±æ•—: {check.__name__}: {e}")
        
        # åˆ†æå•é¡Œåš´é‡æ€§
        critical_errors = len([i for i in self.issues if i.level == "error"])
        warnings = len([i for i in self.issues if i.level == "warning"])
        
        if critical_errors > 0:
            overall_status = "failed"
        elif warnings > 0:
            overall_status = "warnings"
        else:
            overall_status = "passed"
        
        report = ValidationReport(
            timestamp=datetime.now().isoformat(),
            total_checks=total_checks,
            passed_checks=passed_checks,
            issues=self.issues,
            critical_errors=critical_errors,
            warnings=warnings,
            overall_status=overall_status
        )
        
        self._save_report(report)
        self._print_summary(report)
        
        return report
    
    def _check_dimension_consistency(self) -> bool:
        """æª¢æŸ¥ç¶­åº¦é…ç½®ä¸€è‡´æ€§"""
        try:
            # æª¢æŸ¥ Transformer é…ç½®
            transformer_config_path = self.project_root / "configs" / "enhanced_transformer_config.json"
            if transformer_config_path.exists():
                with open(transformer_config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    
                model_dim = config.get('model', {}).get('model_dim', 768)
                num_layers = config.get('model', {}).get('num_layers', 16)
                num_heads = config.get('model', {}).get('num_heads', 24)
                
                # æª¢æŸ¥æ˜¯å¦ç‚ºåˆç†å€¼
                if model_dim % num_heads != 0:
                    self._add_issue("error", "dimension", "enhanced_transformer_config.json",
                                  f"model_dim ({model_dim}) å¿…é ˆè¢« num_heads ({num_heads}) æ•´é™¤",
                                  f"{model_dim} % {num_heads} = {model_dim % num_heads}",
                                  f"èª¿æ•´ model_dim ç‚º {(model_dim // num_heads) * num_heads} æˆ–èª¿æ•´ num_heads")
                    return False
                
        except Exception as e:
            self._add_issue("error", "dimension", "ConfigValidator", f"ç¶­åº¦æª¢æŸ¥å¤±æ•—: {str(e)}")
            return False
            
        return True
    
    def _check_path_validity(self) -> bool:
        """æª¢æŸ¥è·¯å¾‘é…ç½®æœ‰æ•ˆæ€§"""
        try:
            required_dirs = ['data', 'logs', 'weights', 'configs']
            for dir_name in required_dirs:
                dir_path = self.project_root / dir_name
                if not dir_path.exists():
                    self._add_issue("warning", "path", "project_structure",
                                  f"ç›®éŒ„ {dir_name} ä¸å­˜åœ¨", str(dir_path),
                                  f"å‰µå»ºç›®éŒ„: mkdir -p {dir_path}")
                    
            # æª¢æŸ¥ .env æ–‡ä»¶
            env_path = self.project_root / ".env"
            if not env_path.exists():
                self._add_issue("warning", "path", ".env",
                              "ç’°å¢ƒé…ç½®æ–‡ä»¶ä¸å­˜åœ¨", str(env_path),
                              "å‰µå»º .env æ–‡ä»¶ä¸¦è¨­ç½® OANDA API é…ç½®")
                              
        except Exception as e:
            self._add_issue("error", "path", "ConfigValidator", f"è·¯å¾‘æª¢æŸ¥å¤±æ•—: {str(e)}")
            return False
            
        return True
    
    def _check_transformer_config(self) -> bool:
        """æª¢æŸ¥ Transformer é…ç½®åˆç†æ€§"""
        try:
            config_path = self.project_root / "configs" / "enhanced_transformer_config.json"
            if not config_path.exists():
                self._add_issue("warning", "compatibility", "enhanced_transformer_config.json",
                              "å¢å¼· Transformer é…ç½®æ–‡ä»¶ä¸å­˜åœ¨", None,
                              "ä½¿ç”¨é»˜èªé…ç½®æˆ–å‰µå»ºé…ç½®æ–‡ä»¶")
                return True
                
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                
            # æª¢æŸ¥è¨“ç·´åƒæ•¸åˆç†æ€§
            training = config.get('training', {})
            batch_size = training.get('batch_size', 32)
            learning_rate = training.get('learning_rate', 0.0001)
            
            if batch_size <= 0 or batch_size > 256:
                self._add_issue("warning", "value", "enhanced_transformer_config.json",
                              f"batch_size ({batch_size}) å¯èƒ½ä¸åˆç†", batch_size,
                              "å»ºè­°ä½¿ç”¨ 16-64 ä¹‹é–“çš„å€¼")
                              
            if learning_rate <= 0 or learning_rate > 0.01:
                self._add_issue("warning", "value", "enhanced_transformer_config.json",
                              f"learning_rate ({learning_rate}) å¯èƒ½ä¸åˆç†", learning_rate,
                              "å»ºè­°ä½¿ç”¨ 0.0001-0.001 ä¹‹é–“çš„å€¼")
                              
        except Exception as e:
            self._add_issue("error", "compatibility", "enhanced_transformer_config.json", 
                          f"Transformer é…ç½®æª¢æŸ¥å¤±æ•—: {str(e)}")
            return False
            
        return True
    
    def _check_quantum_strategy_config(self) -> bool:
        """æª¢æŸ¥é‡å­ç­–ç•¥å±¤é…ç½®"""
        try:
            # æª¢æŸ¥åŸºç¤é…ç½®æ˜¯å¦å­˜åœ¨
            try:
                from oanda_trading_bot.training_system.common.config import MAX_SYMBOLS_ALLOWED
                if MAX_SYMBOLS_ALLOWED <= 0 or MAX_SYMBOLS_ALLOWED > 50:
                    self._add_issue("warning", "value", "config.py",
                                  f"MAX_SYMBOLS_ALLOWED ({MAX_SYMBOLS_ALLOWED}) å¯èƒ½ä¸åˆç†", 
                                  MAX_SYMBOLS_ALLOWED, "å»ºè­°è¨­ç½®ç‚º 5-20 ä¹‹é–“çš„å€¼")
                else:
                    logger.info(f"âœ“ MAX_SYMBOLS_ALLOWED é…ç½®æ­£å¸¸: {MAX_SYMBOLS_ALLOWED}")
                    
            except ImportError:
                self._add_issue("error", "value", "config.py",
                              "ç„¡æ³•å°å…¥ MAX_SYMBOLS_ALLOWED", None, "æª¢æŸ¥ config.py æ–‡ä»¶")
                return False
                              
        except Exception as e:
            self._add_issue("error", "compatibility", "quantum_strategy", 
                          f"é‡å­ç­–ç•¥é…ç½®æª¢æŸ¥å¤±æ•—: {str(e)}")
            return False
            
        return True
    
    def _check_progressive_learning_config(self) -> bool:
        """æª¢æŸ¥æ¼¸é€²å¼å­¸ç¿’é…ç½®"""
        try:
            config_path = self.project_root / "configs" / "enhanced_transformer_config.json"
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    
                progressive = config.get('progressive_learning', {})
                if not progressive.get('enabled', False):
                    self._add_issue("info", "value", "enhanced_transformer_config.json",
                                  "æ¼¸é€²å¼å­¸ç¿’æœªå•Ÿç”¨", False, "è€ƒæ…®å•Ÿç”¨ä»¥æå‡å­¸ç¿’æ•ˆæœ")
                                  
        except Exception as e:
            self._add_issue("warning", "compatibility", "progressive_learning", 
                          f"æ¼¸é€²å¼å­¸ç¿’é…ç½®æª¢æŸ¥å¤±æ•—: {str(e)}")
            
        return True
    
    def _check_device_compatibility(self) -> bool:
        """æª¢æŸ¥è¨­å‚™å…¼å®¹æ€§"""
        try:
            # æª¢æŸ¥ CUDA å¯ç”¨æ€§
            if torch.cuda.is_available():
                gpu_count = torch.cuda.device_count()
                current_device = torch.cuda.current_device()
                gpu_name = torch.cuda.get_device_name(current_device)
                
                logger.info(f"æª¢æ¸¬åˆ° GPU: {gpu_name} (è¨­å‚™ {current_device}/{gpu_count})")
                
                # æª¢æŸ¥ GPU è¨˜æ†¶é«”
                gpu_memory = torch.cuda.get_device_properties(current_device).total_memory
                gpu_memory_gb = gpu_memory / (1024**3)
                
                if gpu_memory_gb < 4:
                    self._add_issue("warning", "compatibility", "GPU",
                                  f"GPU è¨˜æ†¶é«”è¼ƒå° ({gpu_memory_gb:.1f}GB)", gpu_memory_gb,
                                  "è€ƒæ…®æ¸›å° batch_size æˆ–ä½¿ç”¨ gradient_checkpointing")
            else:
                self._add_issue("info", "compatibility", "GPU",
                              "æœªæª¢æ¸¬åˆ° CUDA GPUï¼Œå°‡ä½¿ç”¨ CPU", "CPU",
                              "å®‰è£ CUDA ç‰ˆæœ¬çš„ PyTorch ä»¥ç²å¾—æ›´å¥½æ€§èƒ½")
                              
        except Exception as e:
            self._add_issue("warning", "compatibility", "device", 
                          f"è¨­å‚™å…¼å®¹æ€§æª¢æŸ¥å¤±æ•—: {str(e)}")
            
        return True
    
    def _check_data_consistency(self) -> bool:
        """æª¢æŸ¥æ•¸æ“šé…ç½®ä¸€è‡´æ€§"""
        try:
            # æª¢æŸ¥æ•¸æ“šç›®éŒ„
            data_dir = self.project_root / "data"
            if data_dir.exists():
                # æª¢æŸ¥ mmap æ•¸æ“š
                mmap_dirs = list(data_dir.glob("mmap*"))
                if mmap_dirs:
                    logger.info(f"ç™¼ç¾ {len(mmap_dirs)} å€‹ mmap æ•¸æ“šç›®éŒ„")
                else:
                    self._add_issue("info", "data", "data_directory",
                                  "æœªç™¼ç¾ mmap æ•¸æ“šç›®éŒ„", None,
                                  "é¦–æ¬¡é‹è¡Œæ™‚æœƒè‡ªå‹•ä¸‹è¼‰å’Œå‰µå»ºæ•¸æ“š")
                                  
        except Exception as e:
            self._add_issue("warning", "data", "data_consistency", 
                          f"æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥å¤±æ•—: {str(e)}")
            
        return True
    
    def _check_training_parameters(self) -> bool:
        """æª¢æŸ¥è¨“ç·´åƒæ•¸åˆç†æ€§"""
        try:
            # æª¢æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„è¨“ç·´åƒæ•¸
            config_path = self.project_root / "configs" / "enhanced_transformer_config.json"
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    
                training = config.get('training', {})
                total_timesteps = training.get('total_timesteps', 2000000)
                
                if total_timesteps < 100000:
                    self._add_issue("warning", "value", "training_parameters",
                                  f"ç¸½è¨“ç·´æ­¥æ•¸è¼ƒå°‘ ({total_timesteps})", total_timesteps,
                                  "å»ºè­°ä½¿ç”¨è‡³å°‘ 500,000 æ­¥ä»¥ç²å¾—è‰¯å¥½æ•ˆæœ")
                elif total_timesteps > 10000000:
                    self._add_issue("warning", "value", "training_parameters",
                                  f"ç¸½è¨“ç·´æ­¥æ•¸è¼ƒå¤š ({total_timesteps})", total_timesteps,
                                  "è€ƒæ…®åˆ†éšæ®µè¨“ç·´æˆ–ä½¿ç”¨æ—©åœæ©Ÿåˆ¶")
                                  
        except Exception as e:
            self._add_issue("warning", "value", "training_parameters", 
                          f"è¨“ç·´åƒæ•¸æª¢æŸ¥å¤±æ•—: {str(e)}")
            
        return True
    
    def _add_issue(self, level: str, category: str, module: str, issue: str, 
                   current_value: Any = None, fix_suggestion: str = ""):
        """æ·»åŠ å•é¡Œåˆ°åˆ—è¡¨"""
        self.issues.append(ConfigIssue(
            level=level,
            category=category,
            module=module,
            issue=issue,
            current_value=current_value,
            fix_suggestion=fix_suggestion
        ))
    
    def _save_report(self, report: ValidationReport):
        """ä¿å­˜é©—è­‰å ±å‘Š"""
        reports_dir = self.project_root / "reports"
        reports_dir.mkdir(exist_ok=True)
        
        report_file = reports_dir / f"config_validation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        # è½‰æ›ç‚ºå¯åºåˆ—åŒ–æ ¼å¼
        report_dict = asdict(report)
        report_dict['issues'] = [asdict(issue) for issue in report.issues]
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_dict, f, indent=2, ensure_ascii=False)
            
        logger.info(f"é©—è­‰å ±å‘Šå·²ä¿å­˜è‡³: {report_file}")
    
    def _print_summary(self, report: ValidationReport):
        """æ‰“å°é©—è­‰æ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ” é…ç½®é©—è­‰å ±å‘Šæ‘˜è¦")
        print("="*60)
        print(f"ç¸½æª¢æŸ¥é …ç›®: {report.total_checks}")
        print(f"é€šéæª¢æŸ¥: {report.passed_checks}")
        print(f"åš´é‡éŒ¯èª¤: {report.critical_errors}")
        print(f"è­¦å‘Š: {report.warnings}")
        print(f"æ•´é«”ç‹€æ…‹: {report.overall_status.upper()}")
        
        if report.issues:
            print(f"\nğŸ“‹ ç™¼ç¾çš„å•é¡Œ:")
            for i, issue in enumerate(report.issues, 1):
                icon = "ğŸš¨" if issue.level == "error" else "âš ï¸" if issue.level == "warning" else "â„¹ï¸"
                print(f"\n{i}. {icon} [{issue.level.upper()}] {issue.module}")
                print(f"   å•é¡Œ: {issue.issue}")
                if issue.current_value is not None:
                    print(f"   ç•¶å‰å€¼: {issue.current_value}")
                if issue.fix_suggestion:
                    print(f"   å»ºè­°: {issue.fix_suggestion}")
        
        print("\n" + "="*60)
    
    def auto_fix(self, report: ValidationReport) -> bool:
        """è‡ªå‹•ä¿®å¾©ä¸€äº›ç°¡å–®å•é¡Œ"""
        logger.info("é–‹å§‹è‡ªå‹•ä¿®å¾©...")
        
        fixed_count = 0
        for issue in report.issues:
            if issue.level == "warning" and issue.category == "path":
                if "ç›®éŒ„" in issue.issue and "ä¸å­˜åœ¨" in issue.issue:
                    # è‡ªå‹•å‰µå»ºç¼ºå¤±ç›®éŒ„
                    try:
                        dir_path = Path(str(issue.current_value))
                        dir_path.mkdir(parents=True, exist_ok=True)
                        logger.info(f"âœ“ å·²å‰µå»ºç›®éŒ„: {dir_path}")
                        fixed_count += 1
                    except Exception as e:
                        logger.error(f"âœ— å‰µå»ºç›®éŒ„å¤±æ•—: {e}")
        
        logger.info(f"è‡ªå‹•ä¿®å¾©å®Œæˆï¼Œå…±ä¿®å¾© {fixed_count} å€‹å•é¡Œ")
        return fixed_count > 0


def main():
    """ä¸»å‡½æ•¸ï¼šåŸ·è¡Œé…ç½®é©—è­‰"""
    validator = ConfigValidator()
    report = validator.validate_all()
    
    if report.overall_status == "failed":
        print("\nâŒ ç™¼ç¾åš´é‡é…ç½®å•é¡Œï¼Œå»ºè­°ä¿®å¾©å¾Œå†é‹è¡Œç³»çµ±")
        return False
    elif report.overall_status == "warnings":
        print("\nâš ï¸ ç™¼ç¾ä¸€äº›é…ç½®è­¦å‘Šï¼Œç³»çµ±å¯ä»¥é‹è¡Œä½†å»ºè­°å„ªåŒ–")
        
        # è©¢å•æ˜¯å¦è‡ªå‹•ä¿®å¾©
        try:
            user_input = input("\næ˜¯å¦å˜—è©¦è‡ªå‹•ä¿®å¾©ï¼Ÿ(y/n): ").lower().strip()
            if user_input in ['y', 'yes', 'æ˜¯']:
                validator.auto_fix(report)
        except KeyboardInterrupt:
            print("\nç”¨æˆ¶å–æ¶ˆæ“ä½œ")
            
        return True
    else:
        print("\nâœ… é…ç½®é©—è­‰é€šéï¼Œç³»çµ±å¯ä»¥æ­£å¸¸é‹è¡Œ")
        return True


if __name__ == "__main__":
    main()
