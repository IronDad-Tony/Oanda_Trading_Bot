#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´æ•´åˆæ¸¬è©¦ç³»çµ± V2.0
ç¢ºä¿æ¯å€‹éšæ®µéƒ½é”åˆ°100%å®Œæˆåº¦ä¸¦å®Œå…¨æ•´åˆ

Version: 2.0
Author: AI Trading System
Date: 2025-06-08
"""

import sys
import os
import time
import traceback
import gc
import psutil
from pathlib import Path
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Any, Optional, Tuple
import logging
import json

import torch
import torch.nn as nn
import numpy as np
import pandas as pd

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/complete_integration_test_v2.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

class CompleteIntegrationTestV2:
    """å®Œæ•´æ•´åˆæ¸¬è©¦ç³»çµ± V2.0"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¸¬è©¦ç³»çµ±"""
        self.project_root = Path(__file__).resolve().parent
        self.src_path = self.project_root / "src"
        
        # æ·»åŠ srcè·¯å¾‘
        if str(self.src_path) not in sys.path:
            sys.path.insert(0, str(self.src_path))
        
        # å‰µå»ºå¿…è¦ç›®éŒ„
        for path in ['logs', 'weights', 'data']:
            (self.project_root / path).mkdir(exist_ok=True)
        
        self.test_results = {}
        self.components = {}
        
        logger.info("ğŸš€ å®Œæ•´æ•´åˆæ¸¬è©¦ç³»çµ± V2.0 åˆå§‹åŒ–å®Œæˆ")
    
    def run_all_tests(self) -> Dict[str, Any]:
        """é‹è¡Œæ‰€æœ‰æ¸¬è©¦"""
        logger.info("="*80)
        logger.info("ğŸ¯ é–‹å§‹å®Œæ•´æ•´åˆæ¸¬è©¦ V2.0")
        logger.info("="*80)
        
        start_time = time.time()
        overall_results = {
            'test_start_time': datetime.now().isoformat(),
            'phases': {},
            'overall_success': False,
            'total_completion_rate': 0.0,
            'critical_issues': [],
            'performance_metrics': {}
        }
        
        try:
            # Phase 1: æ¸¬è©¦åŸºç¤çµ„ä»¶è¼‰å…¥
            logger.info("\nğŸ“‹ Phase 1: åŸºç¤çµ„ä»¶è¼‰å…¥æ¸¬è©¦")
            phase1_results = self.test_component_loading()
            overall_results['phases']['phase1_component_loading'] = phase1_results
            
            # Phase 2: æ¸¬è©¦çµ„ä»¶åŠŸèƒ½
            logger.info("\nğŸ“‹ Phase 2: çµ„ä»¶åŠŸèƒ½æ¸¬è©¦")
            phase2_results = self.test_component_functionality()
            overall_results['phases']['phase2_component_functionality'] = phase2_results
            
            # Phase 3: æ¸¬è©¦çµ„ä»¶æ•´åˆ
            logger.info("\nğŸ“‹ Phase 3: çµ„ä»¶æ•´åˆæ¸¬è©¦")
            phase3_results = self.test_component_integration()
            overall_results['phases']['phase3_component_integration'] = phase3_results
            
            # Phase 4: æ¸¬è©¦çœŸå¯¦æ•¸æ“šè™•ç†
            logger.info("\nğŸ“‹ Phase 4: çœŸå¯¦æ•¸æ“šè™•ç†æ¸¬è©¦")
            phase4_results = self.test_real_data_processing()
            overall_results['phases']['phase4_real_data_processing'] = phase4_results
            
            # Phase 5: æ¸¬è©¦ç³»çµ±æ€§èƒ½
            logger.info("\nğŸ“‹ Phase 5: ç³»çµ±æ€§èƒ½æ¸¬è©¦")
            phase5_results = self.test_system_performance()
            overall_results['phases']['phase5_system_performance'] = phase5_results
            
            # Phase 6: ç«¯åˆ°ç«¯æ¸¬è©¦
            logger.info("\nğŸ“‹ Phase 6: ç«¯åˆ°ç«¯å®Œæ•´æ¸¬è©¦")
            phase6_results = self.test_end_to_end()
            overall_results['phases']['phase6_end_to_end'] = phase6_results
            
            # è¨ˆç®—ç¸½é«”çµæœ
            total_completion = self.calculate_total_completion(overall_results['phases'])
            overall_results['total_completion_rate'] = total_completion
            overall_results['overall_success'] = total_completion >= 80.0
            
        except Exception as e:
            logger.error(f"âŒ æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
            overall_results['critical_issues'].append(f"æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {str(e)}")
            traceback.print_exc()
        
        # å®Œæˆæ¸¬è©¦
        end_time = time.time()
        overall_results['test_end_time'] = datetime.now().isoformat()
        overall_results['total_duration_seconds'] = end_time - start_time
        
        # ä¿å­˜çµæœ
        self.save_test_results(overall_results)
        
        # è¼¸å‡ºç¸½çµ
        self.print_test_summary(overall_results)
        
        return overall_results
    
    def test_component_loading(self) -> Dict[str, Any]:
        """æ¸¬è©¦çµ„ä»¶è¼‰å…¥"""
        results = {
            'components_loaded': {},
            'import_success_rate': 0.0,
            'critical_errors': [],
            'completion_rate': 0.0
        }
        
        components_to_test = [
            ('StrategyInnovationModule', 'agent.strategy_innovation_module'),
            ('MarketStateAwarenessSystem', 'agent.market_state_awareness_system'),
            ('MetaLearningOptimizer', 'agent.meta_learning_optimizer'),
            ('HighLevelIntegrationSystem', 'agent.high_level_integration_system'),
            ('UniversalTradingEnvV4', 'environment.trading_env'),
            ('OandaDownloader', 'data_manager.oanda_downloader'),
            ('DatabaseManager', 'data_manager.database_manager')
        ]
        
        successful_imports = 0
        
        for component_name, module_path in components_to_test:
            try:
                logger.info(f"ğŸ“¦ è¼‰å…¥çµ„ä»¶: {component_name}")
                
                if module_path == 'agent.strategy_innovation_module':
                    from agent.strategy_innovation_module import StrategyInnovationModule
                    component = StrategyInnovationModule(input_dim=768, hidden_dim=768)
                    
                elif module_path == 'agent.market_state_awareness_system':
                    from agent.market_state_awareness_system import MarketStateAwarenessSystem
                    component = MarketStateAwarenessSystem(input_dim=768, num_strategies=20)
                    
                elif module_path == 'agent.meta_learning_optimizer':
                    from agent.meta_learning_optimizer import MetaLearningOptimizer
                    base_model = nn.Linear(768, 1)
                    component = MetaLearningOptimizer(model=base_model, feature_dim=768)
                    
                elif module_path == 'agent.high_level_integration_system':
                    # å…ˆè¼‰å…¥ä¾è³´çµ„ä»¶
                    if 'StrategyInnovationModule' in self.components:
                        from agent.high_level_integration_system import HighLevelIntegrationSystem
                        component = HighLevelIntegrationSystem(
                            strategy_innovation_module=self.components['StrategyInnovationModule'],
                            market_state_awareness_system=self.components['MarketStateAwarenessSystem'],
                            meta_learning_optimizer=self.components['MetaLearningOptimizer']
                        )
                    else:
                        raise Exception("ä¾è³´çµ„ä»¶æœªè¼‰å…¥")
                        
                elif module_path == 'environment.trading_env':
                    from environment.trading_env import UniversalTradingEnvV4
                    component = UniversalTradingEnvV4
                    
                elif module_path == 'data_manager.oanda_downloader':
                    from data_manager.oanda_downloader import manage_data_download_for_symbols
                    component = manage_data_download_for_symbols
                    
                elif module_path == 'data_manager.database_manager':
                    from data_manager.database_manager import query_historical_data
                    component = query_historical_data
                
                self.components[component_name] = component
                results['components_loaded'][component_name] = True
                successful_imports += 1
                logger.info(f"âœ… {component_name} è¼‰å…¥æˆåŠŸ")
                
            except Exception as e:
                error_msg = f"{component_name} è¼‰å…¥å¤±æ•—: {str(e)}"
                logger.error(f"âŒ {error_msg}")
                results['components_loaded'][component_name] = False
                results['critical_errors'].append(error_msg)
        
        results['import_success_rate'] = (successful_imports / len(components_to_test)) * 100
        results['completion_rate'] = results['import_success_rate']
        
        logger.info(f"ğŸ“Š çµ„ä»¶è¼‰å…¥å®Œæˆç‡: {results['completion_rate']:.1f}%")
        return results
    
    def test_component_functionality(self) -> Dict[str, Any]:
        """æ¸¬è©¦çµ„ä»¶åŠŸèƒ½"""
        results = {
            'functionality_tests': {},
            'functional_success_rate': 0.0,
            'errors': [],
            'completion_rate': 0.0
        }
        
        # å‰µå»ºæ¸¬è©¦æ•¸æ“š
        test_data = torch.randn(4, 50, 768)
        successful_tests = 0
        total_tests = 0
        
        # æ¸¬è©¦ç­–ç•¥å‰µæ–°æ¨¡çµ„
        if 'StrategyInnovationModule' in self.components:
            try:
                logger.info("ğŸ§ª æ¸¬è©¦ç­–ç•¥å‰µæ–°æ¨¡çµ„åŠŸèƒ½")
                component = self.components['StrategyInnovationModule']
                
                output = component(test_data)
                
                # é©—è­‰è¼¸å‡º
                required_keys = ['generated_strategies', 'innovation_confidence', 'strategy_diversity']
                tests_passed = 0
                
                for key in required_keys:
                    if key in output:
                        tests_passed += 1
                
                # æª¢æŸ¥æ•¸å€¼ç¯„åœ
                if 'innovation_confidence' in output:
                    confidence = output['innovation_confidence']
                    if 0.0 <= confidence <= 1.0:
                        tests_passed += 1
                
                success_rate = (tests_passed / (len(required_keys) + 1)) * 100
                results['functionality_tests']['StrategyInnovationModule'] = {
                    'success': success_rate >= 75,
                    'success_rate': success_rate,
                    'tests_passed': tests_passed,
                    'total_tests': len(required_keys) + 1
                }
                
                if success_rate >= 75:
                    successful_tests += 1
                    logger.info(f"âœ… ç­–ç•¥å‰µæ–°æ¨¡çµ„æ¸¬è©¦é€šé: {success_rate:.1f}%")
                else:
                    logger.warning(f"âš ï¸ ç­–ç•¥å‰µæ–°æ¨¡çµ„æ¸¬è©¦éƒ¨åˆ†å¤±æ•—: {success_rate:.1f}%")
                
                total_tests += 1
                
            except Exception as e:
                error_msg = f"ç­–ç•¥å‰µæ–°æ¨¡çµ„åŠŸèƒ½æ¸¬è©¦å¤±æ•—: {str(e)}"
                logger.error(f"âŒ {error_msg}")
                results['errors'].append(error_msg)
                results['functionality_tests']['StrategyInnovationModule'] = {
                    'success': False,
                    'error': str(e)
                }
                total_tests += 1
        
        # æ¸¬è©¦å¸‚å ´ç‹€æ…‹æ„ŸçŸ¥ç³»çµ±
        if 'MarketStateAwarenessSystem' in self.components:
            try:
                logger.info("ğŸ§ª æ¸¬è©¦å¸‚å ´ç‹€æ…‹æ„ŸçŸ¥ç³»çµ±åŠŸèƒ½")
                component = self.components['MarketStateAwarenessSystem']
                
                output = component(test_data)
                
                required_keys = ['market_state', 'system_status', 'regime_confidence']
                tests_passed = 0
                
                for key in required_keys:
                    if key in output:
                        tests_passed += 1
                
                # æª¢æŸ¥ç½®ä¿¡åº¦ç¯„åœ
                if 'regime_confidence' in output:
                    confidence = output['regime_confidence']
                    if 0.0 <= confidence <= 1.0:
                        tests_passed += 1
                
                success_rate = (tests_passed / (len(required_keys) + 1)) * 100
                results['functionality_tests']['MarketStateAwarenessSystem'] = {
                    'success': success_rate >= 75,
                    'success_rate': success_rate,
                    'tests_passed': tests_passed,
                    'total_tests': len(required_keys) + 1
                }
                
                if success_rate >= 75:
                    successful_tests += 1
                    logger.info(f"âœ… å¸‚å ´ç‹€æ…‹æ„ŸçŸ¥ç³»çµ±æ¸¬è©¦é€šé: {success_rate:.1f}%")
                else:
                    logger.warning(f"âš ï¸ å¸‚å ´ç‹€æ…‹æ„ŸçŸ¥ç³»çµ±æ¸¬è©¦éƒ¨åˆ†å¤±æ•—: {success_rate:.1f}%")
                
                total_tests += 1
                
            except Exception as e:
                error_msg = f"å¸‚å ´ç‹€æ…‹æ„ŸçŸ¥ç³»çµ±åŠŸèƒ½æ¸¬è©¦å¤±æ•—: {str(e)}"
                logger.error(f"âŒ {error_msg}")
                results['errors'].append(error_msg)
                results['functionality_tests']['MarketStateAwarenessSystem'] = {
                    'success': False,
                    'error': str(e)
                }
                total_tests += 1
        
        # æ¸¬è©¦å…ƒå­¸ç¿’å„ªåŒ–å™¨
        if 'MetaLearningOptimizer' in self.components:
            try:
                logger.info("ğŸ§ª æ¸¬è©¦å…ƒå­¸ç¿’å„ªåŒ–å™¨åŠŸèƒ½")
                component = self.components['MetaLearningOptimizer']
                
                # å‰µå»ºä»»å‹™æ‰¹æ¬¡
                from agent.meta_learning_optimizer import TaskBatch
                task_batches = [
                    TaskBatch(
                        support_data=torch.randn(16, 768),
                        support_labels=torch.randn(16, 1),
                        query_data=torch.randn(8, 768),
                        query_labels=torch.randn(8, 1),
                        task_id="test_task",
                        market_state="trending",
                        difficulty=0.5
                    )
                ]
                
                output = component.optimize_and_adapt(test_data, test_data, task_batches)
                
                required_keys = ['adapted_features', 'selected_strategy', 'adaptation_quality']
                tests_passed = 0
                
                for key in required_keys:
                    if key in output:
                        tests_passed += 1
                
                # æª¢æŸ¥é©æ‡‰è³ªé‡ç¯„åœ
                if 'adaptation_quality' in output:
                    quality = output['adaptation_quality']
                    if 0.0 <= quality <= 1.0:
                        tests_passed += 1
                
                success_rate = (tests_passed / (len(required_keys) + 1)) * 100
                results['functionality_tests']['MetaLearningOptimizer'] = {
                    'success': success_rate >= 75,
                    'success_rate': success_rate,
                    'tests_passed': tests_passed,
                    'total_tests': len(required_keys) + 1
                }
                
                if success_rate >= 75:
                    successful_tests += 1
                    logger.info(f"âœ… å…ƒå­¸ç¿’å„ªåŒ–å™¨æ¸¬è©¦é€šé: {success_rate:.1f}%")
                else:
                    logger.warning(f"âš ï¸ å…ƒå­¸ç¿’å„ªåŒ–å™¨æ¸¬è©¦éƒ¨åˆ†å¤±æ•—: {success_rate:.1f}%")
                
                total_tests += 1
                
            except Exception as e:
                error_msg = f"å…ƒå­¸ç¿’å„ªåŒ–å™¨åŠŸèƒ½æ¸¬è©¦å¤±æ•—: {str(e)}"
                logger.error(f"âŒ {error_msg}")
                results['errors'].append(error_msg)
                results['functionality_tests']['MetaLearningOptimizer'] = {
                    'success': False,
                    'error': str(e)
                }
                total_tests += 1
        
        # è¨ˆç®—ç¸½é«”åŠŸèƒ½æˆåŠŸç‡
        if total_tests > 0:
            results['functional_success_rate'] = (successful_tests / total_tests) * 100
            results['completion_rate'] = results['functional_success_rate']
        
        logger.info(f"ğŸ“Š çµ„ä»¶åŠŸèƒ½æ¸¬è©¦å®Œæˆç‡: {results['completion_rate']:.1f}%")
        return results
    
    def test_component_integration(self) -> Dict[str, Any]:
        """æ¸¬è©¦çµ„ä»¶æ•´åˆ"""
        results = {
            'integration_tests': {},
            'integration_success_rate': 0.0,
            'data_flow_tests': {},
            'errors': [],
            'completion_rate': 0.0
        }
        
        successful_integrations = 0
        total_integrations = 0
        
        # æ¸¬è©¦é«˜éšæ•´åˆç³»çµ±
        if 'HighLevelIntegrationSystem' in self.components:
            try:
                logger.info("ğŸ”— æ¸¬è©¦é«˜éšæ•´åˆç³»çµ±")
                component = self.components['HighLevelIntegrationSystem']
                
                test_data = torch.randn(4, 50, 768)
                
                # æ¸¬è©¦å¸‚å ´æ•¸æ“šè™•ç†
                output = component.process_market_data(test_data)
                
                required_keys = [
                    'market_state', 'strategy_innovation', 'meta_learning',
                    'system_health', 'processing_time'
                ]
                tests_passed = 0
                
                for key in required_keys:
                    if key in output:
                        tests_passed += 1
                
                # æª¢æŸ¥è™•ç†æ™‚é–“
                if 'processing_time' in output and output['processing_time'] < 10.0:
                    tests_passed += 1
                
                # æª¢æŸ¥ç³»çµ±å¥åº·åº¦
                if 'system_health' in output and isinstance(output['system_health'], dict):
                    if 'overall_health' in output['system_health']:
                        health = output['system_health']['overall_health']
                        if 0.0 <= health <= 1.0:
                            tests_passed += 1
                
                success_rate = (tests_passed / (len(required_keys) + 2)) * 100
                results['integration_tests']['HighLevelIntegrationSystem'] = {
                    'success': success_rate >= 75,
                    'success_rate': success_rate,
                    'processing_time': output.get('processing_time', 'N/A')
                }
                
                if success_rate >= 75:
                    successful_integrations += 1
                    logger.info(f"âœ… é«˜éšæ•´åˆç³»çµ±æ¸¬è©¦é€šé: {success_rate:.1f}%")
                else:
                    logger.warning(f"âš ï¸ é«˜éšæ•´åˆç³»çµ±æ¸¬è©¦éƒ¨åˆ†å¤±æ•—: {success_rate:.1f}%")
                
                total_integrations += 1
                
            except Exception as e:
                error_msg = f"é«˜éšæ•´åˆç³»çµ±æ¸¬è©¦å¤±æ•—: {str(e)}"
                logger.error(f"âŒ {error_msg}")
                results['errors'].append(error_msg)
                results['integration_tests']['HighLevelIntegrationSystem'] = {
                    'success': False,
                    'error': str(e)
                }
                total_integrations += 1
        
        # æ¸¬è©¦æ•¸æ“šæµå‹•
        try:
            logger.info("ğŸ”„ æ¸¬è©¦çµ„ä»¶é–“æ•¸æ“šæµå‹•")
            
            if ('StrategyInnovationModule' in self.components and 
                'MarketStateAwarenessSystem' in self.components):
                
                test_data = torch.randn(2, 30, 768)
                
                # æ¸¬è©¦å¸‚å ´ç‹€æ…‹ -> ç­–ç•¥å‰µæ–°
                market_output = self.components['MarketStateAwarenessSystem'](test_data)
                strategy_output = self.components['StrategyInnovationModule'](test_data)
                
                data_flow_success = (
                    'market_state' in market_output and 
                    'generated_strategies' in strategy_output
                )
                
                results['data_flow_tests']['market_to_strategy'] = data_flow_success
                
                if data_flow_success:
                    logger.info("âœ… å¸‚å ´ç‹€æ…‹åˆ°ç­–ç•¥å‰µæ–°æ•¸æ“šæµå‹•æ­£å¸¸")
                else:
                    logger.warning("âš ï¸ å¸‚å ´ç‹€æ…‹åˆ°ç­–ç•¥å‰µæ–°æ•¸æ“šæµå‹•ç•°å¸¸")
                
        except Exception as e:
            error_msg = f"æ•¸æ“šæµå‹•æ¸¬è©¦å¤±æ•—: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            results['errors'].append(error_msg)
            results['data_flow_tests']['market_to_strategy'] = False
        
        # è¨ˆç®—æ•´åˆæˆåŠŸç‡
        if total_integrations > 0:
            results['integration_success_rate'] = (successful_integrations / total_integrations) * 100
        
        # è¨ˆç®—æ•¸æ“šæµæ¸¬è©¦æˆåŠŸç‡
        data_flow_tests = list(results['data_flow_tests'].values())
        if data_flow_tests:
            data_flow_success_rate = (sum(data_flow_tests) / len(data_flow_tests)) * 100
        else:
            data_flow_success_rate = 0.0
        
        # ç¶œåˆå®Œæˆç‡
        results['completion_rate'] = (results['integration_success_rate'] + data_flow_success_rate) / 2
        
        logger.info(f"ğŸ“Š çµ„ä»¶æ•´åˆæ¸¬è©¦å®Œæˆç‡: {results['completion_rate']:.1f}%")
        return results
    
    def test_real_data_processing(self) -> Dict[str, Any]:
        """æ¸¬è©¦çœŸå¯¦æ•¸æ“šè™•ç†"""
        results = {
            'data_access_tests': {},
            'data_processing_tests': {},
            'trading_env_tests': {},
            'errors': [],
            'completion_rate': 0.0
        }
        
        successful_tests = 0
        total_tests = 0
        
        # æ¸¬è©¦æ•¸æ“šåº«é€£æ¥å’ŒæŸ¥è©¢
        try:
            logger.info("ğŸ’¾ æ¸¬è©¦æ•¸æ“šåº«é€£æ¥")
            
            if 'DatabaseManager' in self.components:
                # æ¸¬è©¦æ•¸æ“šæŸ¥è©¢
                end_time = datetime.now(timezone.utc)
                start_time = end_time - timedelta(hours=1)
                
                # æ ¼å¼åŒ–æ™‚é–“
                from data_manager.oanda_downloader import format_datetime_for_oanda
                start_iso = format_datetime_for_oanda(start_time)
                end_iso = format_datetime_for_oanda(end_time)
                
                # å˜—è©¦æŸ¥è©¢æ•¸æ“š
                df = self.components['DatabaseManager']("EUR_USD", "S5", start_iso, end_iso, limit=10)
                
                data_available = not df.empty if isinstance(df, pd.DataFrame) else False
                results['data_access_tests']['database_query'] = data_available
                
                if data_available:
                    logger.info(f"âœ… æ•¸æ“šåº«æŸ¥è©¢æˆåŠŸï¼Œç²å– {len(df)} æ¢è¨˜éŒ„")
                    successful_tests += 1
                else:
                    logger.warning("âš ï¸ æ•¸æ“šåº«æŸ¥è©¢ç„¡æ•¸æ“šè¿”å›")
                
                total_tests += 1
                
        except Exception as e:
            error_msg = f"æ•¸æ“šåº«é€£æ¥æ¸¬è©¦å¤±æ•—: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            results['errors'].append(error_msg)
            results['data_access_tests']['database_query'] = False
            total_tests += 1
        
        # æ¸¬è©¦äº¤æ˜“ç’°å¢ƒ
        try:
            logger.info("ğŸ¢ æ¸¬è©¦äº¤æ˜“ç’°å¢ƒ")
            
            if 'UniversalTradingEnvV4' in self.components:
                env_class = self.components['UniversalTradingEnvV4']
                
                # å‰µå»ºäº¤æ˜“ç’°å¢ƒ
                symbols = ["EUR_USD"]
                end_time = datetime.now(timezone.utc)
                start_time = end_time - timedelta(minutes=30)
                
                trading_env = env_class(
                    symbols=symbols,
                    start_time=start_time,
                    end_time=end_time,
                    initial_capital=10000.0,
                    max_symbols=1
                )
                
                # æ¸¬è©¦ç’°å¢ƒé‡ç½®
                obs = trading_env.reset()
                env_reset_success = obs is not None
                results['trading_env_tests']['env_reset'] = env_reset_success
                
                if env_reset_success:
                    logger.info("âœ… äº¤æ˜“ç’°å¢ƒé‡ç½®æˆåŠŸ")
                    successful_tests += 1
                    
                    # æ¸¬è©¦ç’°å¢ƒæ­¥é©Ÿ
                    try:
                        action = np.random.uniform(-0.1, 0.1, size=trading_env.action_space.shape)
                        obs, reward, done, info = trading_env.step(action)
                        
                        env_step_success = obs is not None and isinstance(reward, (int, float))
                        results['trading_env_tests']['env_step'] = env_step_success
                        
                        if env_step_success:
                            logger.info("âœ… äº¤æ˜“ç’°å¢ƒæ­¥é©ŸåŸ·è¡ŒæˆåŠŸ")
                            successful_tests += 1
                        else:
                            logger.warning("âš ï¸ äº¤æ˜“ç’°å¢ƒæ­¥é©ŸåŸ·è¡Œå¤±æ•—")
                        
                        total_tests += 1
                        
                    except Exception as e:
                        logger.error(f"âŒ äº¤æ˜“ç’°å¢ƒæ­¥é©Ÿæ¸¬è©¦å¤±æ•—: {e}")
                        results['trading_env_tests']['env_step'] = False
                        total_tests += 1
                else:
                    logger.warning("âš ï¸ äº¤æ˜“ç’°å¢ƒé‡ç½®å¤±æ•—")
                
                total_tests += 1
                
        except Exception as e:
            error_msg = f"äº¤æ˜“ç’°å¢ƒæ¸¬è©¦å¤±æ•—: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            results['errors'].append(error_msg)
            results['trading_env_tests']['env_creation'] = False
            total_tests += 1
        
        # è¨ˆç®—å®Œæˆç‡
        if total_tests > 0:
            results['completion_rate'] = (successful_tests / total_tests) * 100
        
        logger.info(f"ğŸ“Š çœŸå¯¦æ•¸æ“šè™•ç†æ¸¬è©¦å®Œæˆç‡: {results['completion_rate']:.1f}%")
        return results
    
    def test_system_performance(self) -> Dict[str, Any]:
        """æ¸¬è©¦ç³»çµ±æ€§èƒ½"""
        results = {
            'latency_tests': {},
            'throughput_tests': {},
            'memory_tests': {},
            'errors': [],
            'completion_rate': 0.0
        }
        
        successful_tests = 0
        total_tests = 0
        
        # å»¶é²æ¸¬è©¦
        try:
            logger.info("âš¡ æ¸¬è©¦ç³»çµ±å»¶é²")
            
            if 'HighLevelIntegrationSystem' in self.components:
                component = self.components['HighLevelIntegrationSystem']
                
                # æ¸¬è©¦å–®æ¬¡è™•ç†å»¶é²
                test_data = torch.randn(1, 50, 768)
                
                latencies = []
                for _ in range(5):
                    start_time = time.time()
                    output = component.process_market_data(test_data)
                    end_time = time.time()
                    latencies.append(end_time - start_time)
                
                avg_latency = np.mean(latencies)
                max_latency = np.max(latencies)
                
                results['latency_tests']['average_latency_seconds'] = avg_latency
                results['latency_tests']['max_latency_seconds'] = max_latency
                results['latency_tests']['latency_acceptable'] = avg_latency < 2.0  # 2ç§’å…§
                
                if avg_latency < 2.0:
                    logger.info(f"âœ… ç³»çµ±å»¶é²æ¸¬è©¦é€šé: {avg_latency:.3f}s")
                    successful_tests += 1
                else:
                    logger.warning(f"âš ï¸ ç³»çµ±å»¶é²è¼ƒé«˜: {avg_latency:.3f}s")
                
                total_tests += 1
                
        except Exception as e:
            error_msg = f"å»¶é²æ¸¬è©¦å¤±æ•—: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            results['errors'].append(error_msg)
            total_tests += 1
        
        # è¨˜æ†¶é«”ä½¿ç”¨æ¸¬è©¦
        try:
            logger.info("ğŸ’¾ æ¸¬è©¦è¨˜æ†¶é«”ä½¿ç”¨")
            
            process = psutil.Process()
            initial_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            # åŸ·è¡Œå¤§æ‰¹é‡è™•ç†
            if 'HighLevelIntegrationSystem' in self.components:
                component = self.components['HighLevelIntegrationSystem']
                large_data = torch.randn(8, 100, 768)
                
                for _ in range(3):
                    output = component.process_market_data(large_data)
                
                peak_memory = process.memory_info().rss / 1024 / 1024  # MB
                
                # æ¸…ç†è¨˜æ†¶é«”
                del large_data, output
                gc.collect()
                
                final_memory = process.memory_info().rss / 1024 / 1024  # MB
                
                memory_increase = peak_memory - initial_memory
                memory_leak = final_memory - initial_memory
                
                results['memory_tests']['initial_memory_mb'] = initial_memory
                results['memory_tests']['peak_memory_mb'] = peak_memory
                results['memory_tests']['final_memory_mb'] = final_memory
                results['memory_tests']['memory_increase_mb'] = memory_increase
                results['memory_tests']['memory_leak_mb'] = memory_leak
                results['memory_tests']['memory_acceptable'] = memory_leak < 50  # å°æ–¼50MBæ´©æ¼
                
                if memory_leak < 50:
                    logger.info(f"âœ… è¨˜æ†¶é«”ä½¿ç”¨æ¸¬è©¦é€šéï¼Œæ´©æ¼: {memory_leak:.1f}MB")
                    successful_tests += 1
                else:
                    logger.warning(f"âš ï¸ è¨˜æ†¶é«”æ´©æ¼è¼ƒå¤š: {memory_leak:.1f}MB")
                
                total_tests += 1
                
        except Exception as e:
            error_msg = f"è¨˜æ†¶é«”æ¸¬è©¦å¤±æ•—: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            results['errors'].append(error_msg)
            total_tests += 1
        
        # è¨ˆç®—å®Œæˆç‡
        if total_tests > 0:
            results['completion_rate'] = (successful_tests / total_tests) * 100
        
        logger.info(f"ğŸ“Š ç³»çµ±æ€§èƒ½æ¸¬è©¦å®Œæˆç‡: {results['completion_rate']:.1f}%")
        return results
    
    def test_end_to_end(self) -> Dict[str, Any]:
        """ç«¯åˆ°ç«¯æ¸¬è©¦"""
        results = {
            'workflow_tests': {},
            'integration_stability': {},
            'real_scenario_tests': {},
            'errors': [],
            'completion_rate': 0.0
        }
        
        successful_tests = 0
        total_tests = 0
        
        try:
            logger.info("ğŸ¯ åŸ·è¡Œç«¯åˆ°ç«¯å·¥ä½œæµç¨‹æ¸¬è©¦")
            
            # å®Œæ•´å·¥ä½œæµç¨‹æ¸¬è©¦
            if 'HighLevelIntegrationSystem' in self.components:
                component = self.components['HighLevelIntegrationSystem']
                
                # 1. å¸‚å ´æ•¸æ“šè¼¸å…¥
                test_data = torch.randn(2, 50, 768)
                
                # 2. è™•ç†å¸‚å ´æ•¸æ“š
                output = component.process_market_data(test_data)
                
                # 3. é©—è­‰è¼¸å‡ºå®Œæ•´æ€§
                required_outputs = [
                    'market_state', 'strategy_innovation', 'meta_learning',
                    'system_health', 'processing_time'
                ]
                
                workflow_success = all(key in output for key in required_outputs)
                results['workflow_tests']['complete_pipeline'] = workflow_success
                
                if workflow_success:
                    logger.info("âœ… å®Œæ•´å·¥ä½œæµç¨‹æ¸¬è©¦é€šé")
                    successful_tests += 1
                else:
                    logger.warning("âš ï¸ å®Œæ•´å·¥ä½œæµç¨‹æ¸¬è©¦å¤±æ•—")
                
                total_tests += 1
                
                # 4. å¤šæ¬¡åŸ·è¡Œç©©å®šæ€§æ¸¬è©¦
                logger.info("ğŸ”„ æ¸¬è©¦å¤šæ¬¡åŸ·è¡Œç©©å®šæ€§")
                stability_success = True
                
                for i in range(3):
                    try:
                        output = component.process_market_data(test_data)
                        if not all(key in output for key in required_outputs):
                            stability_success = False
                            break
                    except Exception as e:
                        logger.error(f"ç©©å®šæ€§æ¸¬è©¦ç¬¬{i+1}æ¬¡å¤±æ•—: {e}")
                        stability_success = False
                        break
                
                results['integration_stability']['multiple_runs'] = stability_success
                
                if stability_success:
                    logger.info("âœ… å¤šæ¬¡åŸ·è¡Œç©©å®šæ€§æ¸¬è©¦é€šé")
                    successful_tests += 1
                else:
                    logger.warning("âš ï¸ å¤šæ¬¡åŸ·è¡Œç©©å®šæ€§æ¸¬è©¦å¤±æ•—")
                
                total_tests += 1
                
        except Exception as e:
            error_msg = f"ç«¯åˆ°ç«¯æ¸¬è©¦å¤±æ•—: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            results['errors'].append(error_msg)
            total_tests += 1
        
        # è¨ˆç®—å®Œæˆç‡
        if total_tests > 0:
            results['completion_rate'] = (successful_tests / total_tests) * 100
        
        logger.info(f"ğŸ“Š ç«¯åˆ°ç«¯æ¸¬è©¦å®Œæˆç‡: {results['completion_rate']:.1f}%")
        return results
    
    def calculate_total_completion(self, phases: Dict[str, Any]) -> float:
        """è¨ˆç®—ç¸½é«”å®Œæˆç‡"""
        completion_rates = []
        
        for phase_name, phase_results in phases.items():
            if isinstance(phase_results, dict) and 'completion_rate' in phase_results:
                completion_rates.append(phase_results['completion_rate'])
        
        if completion_rates:
            return sum(completion_rates) / len(completion_rates)
        else:
            return 0.0
    
    def save_test_results(self, results: Dict[str, Any]):
        """ä¿å­˜æ¸¬è©¦çµæœ"""
        try:
            results_file = self.project_root / "logs" / f"integration_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)
            
            logger.info(f"ğŸ“„ æ¸¬è©¦çµæœå·²ä¿å­˜åˆ°: {results_file}")
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æ¸¬è©¦çµæœå¤±æ•—: {e}")
    
    def print_test_summary(self, results: Dict[str, Any]):
        """å°å‡ºæ¸¬è©¦ç¸½çµ"""
        logger.info("\n" + "="*80)
        logger.info("ğŸ“‹ æ¸¬è©¦ç¸½çµå ±å‘Š")
        logger.info("="*80)
        
        total_completion = results.get('total_completion_rate', 0.0)
        overall_success = results.get('overall_success', False)
        
        # ç‹€æ…‹æŒ‡ç¤º
        status_icon = "âœ…" if overall_success else "âŒ"
        logger.info(f"{status_icon} ç¸½é«”ç‹€æ…‹: {'æˆåŠŸ' if overall_success else 'éœ€è¦æ”¹é€²'}")
        logger.info(f"ğŸ“Š ç¸½é«”å®Œæˆç‡: {total_completion:.1f}%")
        
        # å„éšæ®µè©³æƒ…
        logger.info("\nğŸ“‹ å„éšæ®µå®Œæˆç‡:")
        phases = results.get('phases', {})
        for phase_name, phase_results in phases.items():
            if isinstance(phase_results, dict) and 'completion_rate' in phase_results:
                completion = phase_results['completion_rate']
                icon = "âœ…" if completion >= 80 else "âš ï¸" if completion >= 60 else "âŒ"
                logger.info(f"  {icon} {phase_name}: {completion:.1f}%")
        
        # é—œéµå•é¡Œ
        critical_issues = results.get('critical_issues', [])
        if critical_issues:
            logger.info("\nğŸš¨ é—œéµå•é¡Œ:")
            for issue in critical_issues[:5]:  # åªé¡¯ç¤ºå‰5å€‹
                logger.info(f"  âŒ {issue}")
        
        # æ€§èƒ½æŒ‡æ¨™
        performance = results.get('performance_metrics', {})
        if performance:
            logger.info("\nâš¡ æ€§èƒ½æŒ‡æ¨™:")
            for metric, value in performance.items():
                logger.info(f"  ğŸ“Š {metric}: {value}")
        
        # æ¸¬è©¦æŒçºŒæ™‚é–“
        duration = results.get('total_duration_seconds', 0)
        logger.info(f"\nâ±ï¸ æ¸¬è©¦æŒçºŒæ™‚é–“: {duration:.1f} ç§’")
        
        logger.info("="*80)
        
        # å»ºè­°
        if total_completion < 80:
            logger.info("ğŸ’¡ å»ºè­°:")
            logger.info("  - æª¢æŸ¥å¤±æ•—çš„çµ„ä»¶è¼‰å…¥")
            logger.info("  - ç¢ºèªæ•¸æ“šé€£æ¥è¨­ç½®")
            logger.info("  - æª¢æŸ¥ç³»çµ±ä¾è³´é …")
            logger.info("  - æŸ¥çœ‹è©³ç´°éŒ¯èª¤æ—¥èªŒ")
        else:
            logger.info("ğŸ‰ æ­å–œï¼ç³»çµ±æ•´åˆæ¸¬è©¦åŸºæœ¬é€šéï¼")


def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ å•Ÿå‹•å®Œæ•´æ•´åˆæ¸¬è©¦ç³»çµ± V2.0")
    print("="*80)
    
    try:
        # å‰µå»ºæ¸¬è©¦å¯¦ä¾‹
        test_system = CompleteIntegrationTestV2()
        
        # é‹è¡Œæ‰€æœ‰æ¸¬è©¦
        results = test_system.run_all_tests()
        
        # è¿”å›çµæœ
        return results
        
    except Exception as e:
        logger.error(f"âŒ æ¸¬è©¦ç³»çµ±åŸ·è¡Œå¤±æ•—: {e}")
        traceback.print_exc()
        return None


if __name__ == "__main__":
    # åŸ·è¡Œæ¸¬è©¦
    test_results = main()
    
    if test_results:
        total_completion = test_results.get('total_completion_rate', 0.0)
        success = test_results.get('overall_success', False)
        
        print(f"\nğŸ¯ æœ€çµ‚çµæœ:")
        print(f"âœ… æˆåŠŸ: {'æ˜¯' if success else 'å¦'}")
        print(f"ğŸ“Š å®Œæˆç‡: {total_completion:.1f}%")
        
        if success:
            print("ğŸ‰ ç³»çµ±æ•´åˆæ¸¬è©¦æˆåŠŸå®Œæˆï¼")
        else:
            print("âš ï¸ ç³»çµ±éœ€è¦é€²ä¸€æ­¥æ”¹é€²ã€‚")
    else:
        print("âŒ æ¸¬è©¦åŸ·è¡Œå¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤æ—¥èªŒã€‚")
