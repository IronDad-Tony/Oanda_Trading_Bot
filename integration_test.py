#!/usr/bin/env python3
"""
OANDA AI Trading Bot - æ•´åˆæ¸¬è©¦è…³æœ¬
æ¸¬è©¦æ‰€æœ‰ä¿®å¾©çš„ç›¸å®¹æ€§å’Œç³»çµ±æ•´é«”ç©©å®šæ€§
"""

import sys
import os
import time
import logging
import traceback
from pathlib import Path
from datetime import datetime, timezone, timedelta
from typing import List, Dict, Any, Optional
import numpy as np
import torch
import gc

# ç¢ºä¿èƒ½æ‰¾åˆ°srcæ¨¡çµ„
project_root = Path(__file__).resolve().parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('integration_test.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

class IntegrationTestSuite:
    """æ•´åˆæ¸¬è©¦å¥—ä»¶"""
    
    def __init__(self):
        self.test_results = {}
        self.failed_tests = []
        self.passed_tests = []
        self.start_time = datetime.now()
        
        # æ¸¬è©¦é…ç½®
        self.test_symbols = ["EUR_USD", "USD_JPY"]
        self.test_timesteps = 1000  # çŸ­æœŸæ¸¬è©¦
        self.test_start_time = datetime.now(timezone.utc) - timedelta(days=7)
        self.test_end_time = datetime.now(timezone.utc) - timedelta(days=1)
        
        logger.info("=" * 60)
        logger.info("ğŸ§ª OANDA AI Trading Bot æ•´åˆæ¸¬è©¦é–‹å§‹")
        logger.info("=" * 60)
    
    def run_test(self, test_name: str, test_func) -> bool:
        """åŸ·è¡Œå–®å€‹æ¸¬è©¦"""
        logger.info(f"ğŸ” åŸ·è¡Œæ¸¬è©¦: {test_name}")
        try:
            start_time = time.time()
            result = test_func()
            duration = time.time() - start_time
            
            if result:
                self.passed_tests.append(test_name)
                logger.info(f"âœ… {test_name} - é€šé ({duration:.2f}ç§’)")
            else:
                self.failed_tests.append(test_name)
                logger.error(f"âŒ {test_name} - å¤±æ•— ({duration:.2f}ç§’)")
            
            self.test_results[test_name] = {
                'passed': result,
                'duration': duration,
                'timestamp': datetime.now()
            }
            
            return result
            
        except Exception as e:
            duration = time.time() - start_time if 'start_time' in locals() else 0
            self.failed_tests.append(test_name)
            logger.error(f"âŒ {test_name} - ç•°å¸¸: {e}")
            logger.error(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
            
            self.test_results[test_name] = {
                'passed': False,
                'duration': duration,
                'error': str(e),
                'timestamp': datetime.now()
            }
            
            return False
    
    def test_imports(self) -> bool:
        """æ¸¬è©¦æ‰€æœ‰æ¨¡çµ„å°å…¥"""
        logger.info("æ¸¬è©¦æ¨¡çµ„å°å…¥...")
        
        try:
            # æ¸¬è©¦æ ¸å¿ƒæ¨¡çµ„
            from src.common.config import DEVICE, USE_AMP, LOGS_DIR
            from src.common.logger_setup import logger as common_logger
            from src.common.shared_data_manager import get_shared_data_manager
            
            # æ¸¬è©¦æ•¸æ“šç®¡ç†æ¨¡çµ„
            from src.data_manager.currency_manager import CurrencyDependencyManager
            from src.data_manager.mmap_dataset import UniversalMemoryMappedDataset
            from src.data_manager.database_manager import DatabaseManager
            
            # æ¸¬è©¦ç’°å¢ƒæ¨¡çµ„
            from src.environment.trading_env import UniversalTradingEnvV4
            
            # æ¸¬è©¦ä»£ç†æ¨¡çµ„
            from src.agent.sac_agent_wrapper import SACAgentWrapper
            
            # æ¸¬è©¦è¨“ç·´å™¨æ¨¡çµ„
            from src.trainer.enhanced_trainer_complete import EnhancedUniversalTrainer
            
            logger.info("âœ… æ‰€æœ‰æ ¸å¿ƒæ¨¡çµ„å°å…¥æˆåŠŸ")
            return True
            
        except ImportError as e:
            logger.error(f"âŒ æ¨¡çµ„å°å…¥å¤±æ•—: {e}")
            return False
    
    def test_gpu_setup(self) -> bool:
        """æ¸¬è©¦GPUè¨­ç½®å’Œå„ªåŒ–"""
        logger.info("æ¸¬è©¦GPUè¨­ç½®...")
        
        try:
            # æª¢æŸ¥CUDAå¯ç”¨æ€§
            cuda_available = torch.cuda.is_available()
            logger.info(f"CUDA å¯ç”¨: {cuda_available}")
            
            if cuda_available:
                # æª¢æŸ¥GPUä¿¡æ¯
                gpu_count = torch.cuda.device_count()
                current_device = torch.cuda.current_device()
                gpu_name = torch.cuda.get_device_name(current_device)
                gpu_memory = torch.cuda.get_device_properties(current_device).total_memory / 1024**3
                
                logger.info(f"GPUæ•¸é‡: {gpu_count}")
                logger.info(f"ç•¶å‰GPU: {current_device} - {gpu_name}")
                logger.info(f"GPUè¨˜æ†¶é«”: {gpu_memory:.1f}GB")
                
                # æ¸¬è©¦GPUè¨˜æ†¶é«”æ¸…ç†
                torch.cuda.empty_cache()
                gc.collect()
                
                # æ¸¬è©¦åŸºæœ¬GPUæ“ä½œ
                test_tensor = torch.randn(100, 100).cuda()
                result = torch.matmul(test_tensor, test_tensor.T)
                logger.info(f"GPUè¨ˆç®—æ¸¬è©¦: {result.shape}")
                
                # æ¸…ç†æ¸¬è©¦å¼µé‡
                del test_tensor, result
                torch.cuda.empty_cache()
                
            logger.info("âœ… GPUè¨­ç½®æ¸¬è©¦å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ GPUè¨­ç½®æ¸¬è©¦å¤±æ•—: {e}")
            return False
    
    def test_shared_data_manager(self) -> bool:
        """æ¸¬è©¦å…±äº«æ•¸æ“šç®¡ç†å™¨"""
        logger.info("æ¸¬è©¦å…±äº«æ•¸æ“šç®¡ç†å™¨...")
        
        try:
            from src.common.shared_data_manager import get_shared_data_manager
            
            # ç²å–å…±äº«æ•¸æ“šç®¡ç†å™¨å¯¦ä¾‹
            manager = get_shared_data_manager()
            
            # æ¸¬è©¦ç‹€æ…‹æ›´æ–°
            manager.update_training_status('running', 50)
            status = manager.get_current_status()
            assert status['status'] == 'running'
            assert status['progress'] == 50
            
            # æ¸¬è©¦åœæ­¢è«‹æ±‚
            manager.request_stop()
            assert manager.is_stop_requested() == True
            manager.reset_stop_flag()
            assert manager.is_stop_requested() == False
            
            # æ¸¬è©¦æŒ‡æ¨™æ·»åŠ 
            manager.add_training_metric(
                step=100,
                reward=1.5,
                portfolio_value=105000,
                actor_loss=0.1,
                critic_loss=0.2
            )
            
            metrics = manager.get_latest_metrics(1)
            assert len(metrics) == 1
            assert metrics[0]['step'] == 100
            assert metrics[0]['reward'] == 1.5
            
            # æ¸¬è©¦äº¤æ˜“è¨˜éŒ„
            manager.add_trade_record(
                symbol='EUR_USD',
                action='buy',
                price=1.1000,
                quantity=10000,
                profit_loss=50.0
            )
            
            trades = manager.get_latest_trades(1)
            assert len(trades) == 1
            assert trades[0]['symbol'] == 'EUR_USD'
            
            logger.info("âœ… å…±äº«æ•¸æ“šç®¡ç†å™¨æ¸¬è©¦é€šé")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å…±äº«æ•¸æ“šç®¡ç†å™¨æ¸¬è©¦å¤±æ•—: {e}")
            return False
    
    def test_file_management(self) -> bool:
        """æ¸¬è©¦æª”æ¡ˆç®¡ç†å’Œè·¯å¾‘é…ç½®"""
        logger.info("æ¸¬è©¦æª”æ¡ˆç®¡ç†...")
        
        try:
            # æª¢æŸ¥é‡è¦ç›®éŒ„
            required_dirs = ['src', 'logs', 'data']
            for dir_name in required_dirs:
                dir_path = Path(dir_name)
                if not dir_path.exists():
                    dir_path.mkdir(parents=True, exist_ok=True)
                    logger.info(f"å‰µå»ºç›®éŒ„: {dir_path}")
                assert dir_path.exists(), f"ç›®éŒ„ä¸å­˜åœ¨: {dir_name}"
            
            # æª¢æŸ¥weightsç›®éŒ„
            weights_dir = Path('weights')
            if not weights_dir.exists():
                weights_dir.mkdir(parents=True, exist_ok=True)
                logger.info(f"å‰µå»ºweightsç›®éŒ„: {weights_dir}")
            
            # æ¸¬è©¦æ—¥èªŒæª”æ¡ˆå‰µå»º
            test_log_file = Path('logs/integration_test.log')
            test_log_file.parent.mkdir(parents=True, exist_ok=True)
            with open(test_log_file, 'w', encoding='utf-8') as f:
                f.write(f"Integration test log - {datetime.now()}\n")
            
            assert test_log_file.exists(), "æ¸¬è©¦æ—¥èªŒæª”æ¡ˆå‰µå»ºå¤±æ•—"
            
            # æ¸…ç†æ¸¬è©¦æª”æ¡ˆ
            test_log_file.unlink()
            
            logger.info("âœ… æª”æ¡ˆç®¡ç†æ¸¬è©¦é€šé")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æª”æ¡ˆç®¡ç†æ¸¬è©¦å¤±æ•—: {e}")
            return False
    
    def test_mmap_cleanup(self) -> bool:
        """æ¸¬è©¦mmapæª”æ¡ˆæ¸…ç†æ©Ÿåˆ¶"""
        logger.info("æ¸¬è©¦mmapæª”æ¡ˆæ¸…ç†...")
        
        try:
            from src.data_manager.mmap_dataset import UniversalMemoryMappedDataset
            
            # å‰µå»ºæ¸¬è©¦æ•¸æ“šé›†ï¼ˆå°è¦æ¨¡ï¼‰
            dataset = UniversalMemoryMappedDataset(
                symbols=self.test_symbols,
                start_time=self.test_start_time,
                end_time=self.test_end_time,
                granularity="M1",  # ä½¿ç”¨åˆ†é˜æ•¸æ“šæ¸›å°‘æ•¸æ“šé‡
                timesteps=50
            )
            
            # æª¢æŸ¥æ•¸æ“šé›†æ˜¯å¦æœ‰æ•ˆ
            if dataset.is_valid():
                logger.info(f"æ¸¬è©¦æ•¸æ“šé›†å‰µå»ºæˆåŠŸï¼Œæ¨£æœ¬æ•¸: {len(dataset)}")
                
                # æ¸¬è©¦æ•¸æ“šè¨ªå•
                if len(dataset) > 0:
                    sample = dataset[0]
                    logger.info(f"æ¨£æœ¬å½¢ç‹€: {sample[0].shape if hasattr(sample[0], 'shape') else 'N/A'}")
                
                # æ¸…ç†æ•¸æ“šé›†
                dataset.cleanup()
                logger.info("æ•¸æ“šé›†æ¸…ç†å®Œæˆ")
            else:
                logger.warning("æ¸¬è©¦æ•¸æ“šé›†ç„¡æ•ˆï¼Œå¯èƒ½æ˜¯æ•¸æ“šä¸è¶³")
            
            logger.info("âœ… mmapæª”æ¡ˆæ¸…ç†æ¸¬è©¦é€šé")
            return True
            
        except Exception as e:
            logger.error(f"âŒ mmapæª”æ¡ˆæ¸…ç†æ¸¬è©¦å¤±æ•—: {e}")
            return False
    
    def test_trainer_initialization(self) -> bool:
        """æ¸¬è©¦è¨“ç·´å™¨åˆå§‹åŒ–"""
        logger.info("æ¸¬è©¦è¨“ç·´å™¨åˆå§‹åŒ–...")
        
        try:
            from src.trainer.enhanced_trainer_complete import EnhancedUniversalTrainer
            
            # å‰µå»ºè¨“ç·´å™¨å¯¦ä¾‹
            trainer = EnhancedUniversalTrainer(
                trading_symbols=self.test_symbols,
                start_time=self.test_start_time,
                end_time=self.test_end_time,
                granularity="M1",
                total_timesteps=self.test_timesteps,
                save_freq=500,
                eval_freq=500,
                model_name_prefix="integration_test"
            )
            
            logger.info(f"è¨“ç·´å™¨å‰µå»ºæˆåŠŸ")
            logger.info(f"äº¤æ˜“å“ç¨®: {trainer.trading_symbols}")
            logger.info(f"æ¨¡å‹è­˜åˆ¥ç¢¼: {trainer.model_identifier}")
            
            # æ¸¬è©¦æ¸…ç†
            trainer.cleanup()
            
            logger.info("âœ… è¨“ç·´å™¨åˆå§‹åŒ–æ¸¬è©¦é€šé")
            return True
            
        except Exception as e:
            logger.error(f"âŒ è¨“ç·´å™¨åˆå§‹åŒ–æ¸¬è©¦å¤±æ•—: {e}")
            return False
    
    def test_streamlit_compatibility(self) -> bool:
        """æ¸¬è©¦Streamlitç›¸å®¹æ€§"""
        logger.info("æ¸¬è©¦Streamlitç›¸å®¹æ€§...")
        
        try:
            # æª¢æŸ¥Streamlitæ‡‰ç”¨æª”æ¡ˆ
            streamlit_files = [
                'streamlit_app_complete.py',
                'streamlit_app.py'
            ]
            
            found_files = []
            for file_name in streamlit_files:
                file_path = Path(file_name)
                if file_path.exists():
                    found_files.append(file_name)
                    logger.info(f"æ‰¾åˆ°Streamlitæª”æ¡ˆ: {file_name}")
            
            assert len(found_files) > 0, "æœªæ‰¾åˆ°Streamlitæ‡‰ç”¨æª”æ¡ˆ"
            
            # æ¸¬è©¦å°å…¥Streamlitç›¸é—œæ¨¡çµ„
            try:
                import streamlit as st
                import plotly.graph_objects as go
                import plotly.express as px
                logger.info("Streamlitç›¸é—œæ¨¡çµ„å°å…¥æˆåŠŸ")
            except ImportError as e:
                logger.warning(f"Streamlitæ¨¡çµ„å°å…¥å¤±æ•—: {e}")
                return False
            
            logger.info("âœ… Streamlitç›¸å®¹æ€§æ¸¬è©¦é€šé")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Streamlitç›¸å®¹æ€§æ¸¬è©¦å¤±æ•—: {e}")
            return False
    
    def test_configuration_consistency(self) -> bool:
        """æ¸¬è©¦é…ç½®ä¸€è‡´æ€§"""
        logger.info("æ¸¬è©¦é…ç½®ä¸€è‡´æ€§...")
        
        try:
            from src.common.config import (
                DEVICE, USE_AMP, LOGS_DIR, TIMESTEPS,
                ACCOUNT_CURRENCY, INITIAL_CAPITAL
            )
            
            # æª¢æŸ¥é—œéµé…ç½®
            config_checks = {
                'DEVICE': DEVICE in ['cpu', 'cuda', 'auto'],
                'USE_AMP': isinstance(USE_AMP, bool),
                'LOGS_DIR': isinstance(LOGS_DIR, (str, type(None))),
                'TIMESTEPS': isinstance(TIMESTEPS, int) and TIMESTEPS > 0,
                'ACCOUNT_CURRENCY': isinstance(ACCOUNT_CURRENCY, str) and len(ACCOUNT_CURRENCY) == 3,
                'INITIAL_CAPITAL': isinstance(INITIAL_CAPITAL, (int, float)) and INITIAL_CAPITAL > 0
            }
            
            for config_name, is_valid in config_checks.items():
                if not is_valid:
                    logger.error(f"é…ç½®æª¢æŸ¥å¤±æ•—: {config_name}")
                    return False
                logger.info(f"é…ç½®æª¢æŸ¥é€šé: {config_name}")
            
            logger.info("âœ… é…ç½®ä¸€è‡´æ€§æ¸¬è©¦é€šé")
            return True
            
        except Exception as e:
            logger.error(f"âŒ é…ç½®ä¸€è‡´æ€§æ¸¬è©¦å¤±æ•—: {e}")
            return False
    
    def run_all_tests(self) -> Dict[str, Any]:
        """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦"""
        logger.info("é–‹å§‹åŸ·è¡Œå®Œæ•´æ¸¬è©¦å¥—ä»¶...")
        
        # å®šç¾©æ¸¬è©¦é †åº
        tests = [
            ("æ¨¡çµ„å°å…¥æ¸¬è©¦", self.test_imports),
            ("GPUè¨­ç½®æ¸¬è©¦", self.test_gpu_setup),
            ("å…±äº«æ•¸æ“šç®¡ç†å™¨æ¸¬è©¦", self.test_shared_data_manager),
            ("æª”æ¡ˆç®¡ç†æ¸¬è©¦", self.test_file_management),
            ("mmapæ¸…ç†æ¸¬è©¦", self.test_mmap_cleanup),
            ("è¨“ç·´å™¨åˆå§‹åŒ–æ¸¬è©¦", self.test_trainer_initialization),
            ("Streamlitç›¸å®¹æ€§æ¸¬è©¦", self.test_streamlit_compatibility),
            ("é…ç½®ä¸€è‡´æ€§æ¸¬è©¦", self.test_configuration_consistency)
        ]
        
        # åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
        for test_name, test_func in tests:
            self.run_test(test_name, test_func)
            time.sleep(1)  # æ¸¬è©¦é–“éš”
        
        # ç”Ÿæˆæ¸¬è©¦å ±å‘Š
        return self.generate_report()
    
    def generate_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
        end_time = datetime.now()
        total_duration = (end_time - self.start_time).total_seconds()
        
        total_tests = len(self.test_results)
        passed_count = len(self.passed_tests)
        failed_count = len(self.failed_tests)
        success_rate = (passed_count / total_tests * 100) if total_tests > 0 else 0
        
        report = {
            'summary': {
                'total_tests': total_tests,
                'passed': passed_count,
                'failed': failed_count,
                'success_rate': success_rate,
                'total_duration': total_duration,
                'start_time': self.start_time,
                'end_time': end_time
            },
            'passed_tests': self.passed_tests,
            'failed_tests': self.failed_tests,
            'detailed_results': self.test_results
        }
        
        # è¼¸å‡ºå ±å‘Š
        logger.info("=" * 60)
        logger.info("ğŸ“Š æ•´åˆæ¸¬è©¦å ±å‘Š")
        logger.info("=" * 60)
        logger.info(f"ç¸½æ¸¬è©¦æ•¸: {total_tests}")
        logger.info(f"é€šéæ¸¬è©¦: {passed_count}")
        logger.info(f"å¤±æ•—æ¸¬è©¦: {failed_count}")
        logger.info(f"æˆåŠŸç‡: {success_rate:.1f}%")
        logger.info(f"ç¸½è€—æ™‚: {total_duration:.2f}ç§’")
        
        if self.passed_tests:
            logger.info("\nâœ… é€šéçš„æ¸¬è©¦:")
            for test in self.passed_tests:
                duration = self.test_results[test]['duration']
                logger.info(f"  - {test} ({duration:.2f}ç§’)")
        
        if self.failed_tests:
            logger.info("\nâŒ å¤±æ•—çš„æ¸¬è©¦:")
            for test in self.failed_tests:
                duration = self.test_results[test]['duration']
                error = self.test_results[test].get('error', 'æœªçŸ¥éŒ¯èª¤')
                logger.info(f"  - {test} ({duration:.2f}ç§’) - {error}")
        
        logger.info("=" * 60)
        
        if success_rate >= 80:
            logger.info("ğŸ‰ æ•´åˆæ¸¬è©¦æ•´é«”é€šéï¼ç³»çµ±æº–å‚™å°±ç·’ã€‚")
        elif success_rate >= 60:
            logger.warning("âš ï¸ æ•´åˆæ¸¬è©¦éƒ¨åˆ†é€šéï¼Œå»ºè­°æª¢æŸ¥å¤±æ•—çš„æ¸¬è©¦ã€‚")
        else:
            logger.error("âŒ æ•´åˆæ¸¬è©¦å¤±æ•—ç‡éé«˜ï¼Œéœ€è¦ä¿®å¾©å•é¡Œå¾Œé‡æ–°æ¸¬è©¦ã€‚")
        
        return report


def main():
    """ä¸»å‡½æ•¸"""
    try:
        # å‰µå»ºæ¸¬è©¦å¥—ä»¶
        test_suite = IntegrationTestSuite()
        
        # åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
        report = test_suite.run_all_tests()
        
        # ä¿å­˜å ±å‘Šåˆ°æª”æ¡ˆ
        import json
        report_file = Path('integration_test_report.json')
        with open(report_file, 'w', encoding='utf-8') as f:
            # è½‰æ›datetimeå°è±¡ç‚ºå­—ç¬¦ä¸²
            def datetime_converter(obj):
                if isinstance(obj, datetime):
                    return obj.isoformat()
                raise TypeError(f"Object of type {type(obj)} is not JSON serializable")
            
            json.dump(report, f, ensure_ascii=False, indent=2, default=datetime_converter)
        
        logger.info(f"è©³ç´°æ¸¬è©¦å ±å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
        # è¿”å›æˆåŠŸç‡
        success_rate = report['summary']['success_rate']
        return success_rate >= 80
        
    except Exception as e:
        logger.error(f"æ•´åˆæ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
        logger.error(traceback.format_exc())
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)