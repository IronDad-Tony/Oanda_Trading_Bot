#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…ƒå­¸ç¿’ç³»çµ±åŠŸèƒ½æ¸¬è©¦
æ¸¬è©¦MAMLå­¸ç¿’å™¨ã€ç­–ç•¥è¨˜æ†¶åº«å’ŒçŸ¥è­˜è’¸é¤¾å™¨çš„åŠŸèƒ½
"""

import torch
import torch.nn as nn
import numpy as np
import sys
import os
from typing import Dict, List, Tuple

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

try:
    from src.agent.meta_learning_system import (
        MetaLearningSystem, 
        TaskDefinition, 
        MAMLLearner, 
        StrategyMemoryBank,
        KnowledgeDistiller
    )
    from src.agent.enhanced_quantum_strategy_layer import EnhancedStrategySuperposition
    from src.environment.progressive_reward_system import ProgressiveRewardSystem
except ImportError as e:
    print(f"å°å…¥éŒ¯èª¤: {e}")
    print("è«‹ç¢ºä¿åœ¨é …ç›®æ ¹ç›®éŒ„é‹è¡Œæ­¤æ¸¬è©¦")
    sys.exit(1)


def create_mock_strategy_model():
    """å‰µå»ºæ¨¡æ“¬ç­–ç•¥æ¨¡å‹"""
    class MockStrategyModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.state_dim = 64
            self.num_strategies = 20
            self.action_dim = 3
            
            # ç°¡å–®çš„ç·šæ€§å±¤
            self.fc = nn.Linear(self.state_dim, self.action_dim)
        
        def forward(self, x):
            return self.fc(x)
    
    return MockStrategyModel()


def test_strategy_memory_bank():
    """æ¸¬è©¦ç­–ç•¥è¨˜æ†¶åº«"""
    print("\n=== æ¸¬è©¦ç­–ç•¥è¨˜æ†¶åº« ===")
    
    memory_bank = StrategyMemoryBank(max_strategies=10)
    
    # å‰µå»ºæ¸¬è©¦ä»»å‹™
    task1 = TaskDefinition(
        task_id="test_1",
        market_regime="trending",
        time_horizon="short",
        risk_profile="moderate",
        asset_class="forex"
    )
    
    task2 = TaskDefinition(
        task_id="test_2", 
        market_regime="ranging",
        time_horizon="medium",
        risk_profile="conservative",
        asset_class="forex"
    )
    
    # æ·»åŠ ç­–ç•¥
    embedding1 = torch.randn(128)
    parameters1 = {"weight": torch.randn(10, 5), "bias": torch.randn(10)}
    performance1 = {"sharpe_ratio": 1.5, "max_drawdown": 0.1}
    
    embedding2 = torch.randn(128)
    parameters2 = {"weight": torch.randn(10, 5), "bias": torch.randn(10)}
    performance2 = {"sharpe_ratio": 1.2, "max_drawdown": 0.15}
    
    memory_bank.add_strategy(embedding1, parameters1, performance1, task1)
    memory_bank.add_strategy(embedding2, parameters2, performance2, task2)
    
    print(f"âœ“ æˆåŠŸæ·»åŠ 2å€‹ç­–ç•¥åˆ°è¨˜æ†¶åº«")
    print(f"  è¨˜æ†¶åº«å¤§å°: {len(memory_bank.strategy_embeddings)}")
    
    # æª¢ç´¢ç›¸ä¼¼ç­–ç•¥
    query_embedding = torch.randn(128)
    similar_strategies = memory_bank.retrieve_similar_strategies(
        query_embedding, task1, top_k=2
    )
    
    print(f"âœ“ æª¢ç´¢åˆ° {len(similar_strategies)} å€‹ç›¸ä¼¼ç­–ç•¥")
    for i, (idx, score, params) in enumerate(similar_strategies):
        print(f"  ç­–ç•¥ {i+1}: ç´¢å¼•={idx}, ç›¸ä¼¼åº¦={score:.4f}")
    
    # ç²å–æœ€ä½³ç­–ç•¥
    best_strategies = memory_bank.get_best_strategies_for_task(task1, top_k=1)
    print(f"âœ“ ç²å–åˆ° {len(best_strategies)} å€‹æœ€ä½³ç­–ç•¥")
    
    return True


def test_maml_learner():
    """æ¸¬è©¦MAMLå­¸ç¿’å™¨"""
    print("\n=== æ¸¬è©¦MAMLå­¸ç¿’å™¨ ===")
    
    # å‰µå»ºåŸºç¤æ¨¡å‹
    base_model = create_mock_strategy_model()
    
    # å‰µå»ºMAMLå­¸ç¿’å™¨
    maml = MAMLLearner(
        base_model=base_model,
        inner_lr=0.01,
        outer_lr=0.001,
        num_inner_steps=3
    )
    
    print(f"âœ“ å‰µå»ºMAMLå­¸ç¿’å™¨")
    print(f"  å…§å±¤å­¸ç¿’ç‡: {maml.inner_lr}")
    print(f"  å¤–å±¤å­¸ç¿’ç‡: {maml.outer_lr}")
    print(f"  å…§å±¤æ­¥æ•¸: {maml.num_inner_steps}")
    
    # æ¸¬è©¦å…§å±¤æ›´æ–°
    support_data = (torch.randn(10, 64), torch.randn(10, 3))
    
    def mock_loss_fn(model, data):
        x, y = data
        pred = model(x)
        return nn.MSELoss()(pred, y)
    
    try:
        fast_model = maml.inner_update(support_data, mock_loss_fn)
        print(f"âœ“ å…§å±¤æ›´æ–°æˆåŠŸ")
        print(f"  å¿«é€Ÿé©æ‡‰æ¨¡å‹é¡å‹: {type(fast_model).__name__}")
    except Exception as e:
        print(f"âœ— å…§å±¤æ›´æ–°å¤±æ•—: {e}")
        return False
    
    return True


def test_knowledge_distiller():
    """æ¸¬è©¦çŸ¥è­˜è’¸é¤¾å™¨"""
    print("\n=== æ¸¬è©¦çŸ¥è­˜è’¸é¤¾å™¨ ===")
    
    # å‰µå»ºæ•™å¸«å’Œå­¸ç”Ÿæ¨¡å‹
    teacher_model = create_mock_strategy_model()
    student_model = create_mock_strategy_model()
    
    # å‰µå»ºçŸ¥è­˜è’¸é¤¾å™¨
    distiller = KnowledgeDistiller(
        teacher_model=teacher_model,
        student_model=student_model,
        temperature=3.0,
        alpha=0.7
    )
    
    print(f"âœ“ å‰µå»ºçŸ¥è­˜è’¸é¤¾å™¨")
    print(f"  æº«åº¦åƒæ•¸: {distiller.temperature}")
    print(f"  è’¸é¤¾æ¬Šé‡: {distiller.alpha}")
    
    # æ¸¬è©¦è’¸é¤¾æå¤±è¨ˆç®—
    student_logits = torch.randn(10, 3)
    teacher_logits = torch.randn(10, 3)
    true_labels = torch.randint(0, 3, (10,))
    
    try:
        distill_loss = distiller.compute_distillation_loss(
            student_logits, teacher_logits, true_labels
        )
        print(f"âœ“ è’¸é¤¾æå¤±è¨ˆç®—æˆåŠŸ: {distill_loss.item():.4f}")
    except Exception as e:
        print(f"âœ— è’¸é¤¾æå¤±è¨ˆç®—å¤±æ•—: {e}")
        return False
    
    return True


def test_meta_learning_system():
    """æ¸¬è©¦å®Œæ•´çš„å…ƒå­¸ç¿’ç³»çµ±"""
    print("\n=== æ¸¬è©¦å…ƒå­¸ç¿’ç³»çµ± ===")
    
    # å‰µå»ºç­–ç•¥æ¨¡å‹
    strategy_model = EnhancedStrategySuperposition(
        state_dim=64,
        action_dim=3,
        num_strategies=20
    )
    
    # å‰µå»ºæ¼¸é€²å¼çå‹µç³»çµ±
    reward_system = ProgressiveRewardSystem(
        state_dim=64,
        action_dim=3
    )
    
    # å‰µå»ºå…ƒå­¸ç¿’ç³»çµ±
    try:
        meta_system = MetaLearningSystem(
            strategy_model=strategy_model,
            reward_system=reward_system,
            config={
                'embedding_dim': 128,
                'memory_size': 100,
                'inner_lr': 0.01,
                'outer_lr': 0.001,
                'num_inner_steps': 5,
                'distill_temperature': 3.0,
                'distill_alpha': 0.7
            }
        )
        print(f"âœ“ å…ƒå­¸ç¿’ç³»çµ±å‰µå»ºæˆåŠŸ")
    except Exception as e:
        print(f"âœ— å…ƒå­¸ç¿’ç³»çµ±å‰µå»ºå¤±æ•—: {e}")
        return False
    
    # æ¸¬è©¦ç­–ç•¥ç·¨ç¢¼
    try:
        state = torch.randn(1, 64)
        strategy_weights = torch.randn(1, 20)
        
        embedding = meta_system.encode_strategy(state, strategy_weights)
        print(f"âœ“ ç­–ç•¥ç·¨ç¢¼æˆåŠŸï¼ŒåµŒå…¥ç¶­åº¦: {embedding.shape}")
    except Exception as e:
        print(f"âœ— ç­–ç•¥ç·¨ç¢¼å¤±æ•—: {e}")
        return False
    
    # æ¸¬è©¦ä»»å‹™ç·¨ç¢¼
    try:
        task = TaskDefinition(
            task_id="test_task",
            market_regime="trending", 
            time_horizon="short",
            risk_profile="moderate",
            asset_class="forex"
        )
        
        task_embedding = meta_system.encode_task(task)
        print(f"âœ“ ä»»å‹™ç·¨ç¢¼æˆåŠŸï¼ŒåµŒå…¥ç¶­åº¦: {task_embedding.shape}")
    except Exception as e:
        print(f"âœ— ä»»å‹™ç·¨ç¢¼å¤±æ•—: {e}")
        return False
    
    # æ¸¬è©¦å¿«é€Ÿé©æ‡‰
    try:
        support_states = torch.randn(10, 64)
        support_actions = torch.randn(10, 3)
        query_states = torch.randn(5, 64)
        
        adapted_params = meta_system.fast_adapt(
            support_states, support_actions, query_states, task
        )
        print(f"âœ“ å¿«é€Ÿé©æ‡‰æˆåŠŸï¼Œåƒæ•¸æ•¸é‡: {len(adapted_params)}")
    except Exception as e:
        print(f"âœ— å¿«é€Ÿé©æ‡‰å¤±æ•—: {e}")
        return False
    
    # æ¸¬è©¦åƒæ•¸åˆ†æ
    try:
        analysis = meta_system.analyze_model_parameters()
        print(f"âœ“ åƒæ•¸åˆ†ææˆåŠŸ")
        print(f"  ç¸½åƒæ•¸é‡: {analysis['total_params']:,}")
        print(f"  ç­–ç•¥ç·¨ç¢¼å™¨åƒæ•¸: {analysis['strategy_encoder_params']:,}")
        print(f"  ä»»å‹™ç·¨ç¢¼å™¨åƒæ•¸: {analysis['task_encoder_params']:,}")
    except Exception as e:
        print(f"âœ— åƒæ•¸åˆ†æå¤±æ•—: {e}")
        return False
    
    return True


def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸš€ é–‹å§‹å…ƒå­¸ç¿’ç³»çµ±åŠŸèƒ½æ¸¬è©¦...")
    
    tests = [
        ("ç­–ç•¥è¨˜æ†¶åº«", test_strategy_memory_bank),
        ("MAMLå­¸ç¿’å™¨", test_maml_learner), 
        ("çŸ¥è­˜è’¸é¤¾å™¨", test_knowledge_distiller),
        ("å®Œæ•´å…ƒå­¸ç¿’ç³»çµ±", test_meta_learning_system)
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âœ— {test_name}æ¸¬è©¦å‡ºç¾ç•°å¸¸: {e}")
            results.append((test_name, False))
    
    # è¼¸å‡ºç¸½çµ
    print("\n" + "="*50)
    print("ğŸ“Š æ¸¬è©¦çµæœç¸½çµ:")
    print("="*50)
    
    passed = 0
    for test_name, result in results:
        status = "âœ… é€šé" if result else "âŒ å¤±æ•—"
        print(f"{test_name:20} {status}")
        if result:
            passed += 1
    
    print(f"\né€šéç‡: {passed}/{len(results)} ({passed/len(results)*100:.1f}%)")
    
    if passed == len(results):
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼å…ƒå­¸ç¿’ç³»çµ±åŠŸèƒ½æ­£å¸¸")
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥å•é¡Œ")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
