import unittest
import sys
import os
import torch
import numpy as np

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..")))

class TestCompleteTrainingFlow(unittest.TestCase):
    """æ¸¬è©¦å®Œæ•´è¨“ç·´æµç¨‹ - ç¢ºä¿æ‰€æœ‰æ¨¡çµ„å”ä½œæ­£å¸¸ï¼Œæ¢¯åº¦æµé€šæš¢ï¼Œæ¬Šé‡æ›´æ–°æ­£ç¢º"""
    
    def setUp(self):
        """è¨­ç½®æ¸¬è©¦ç’°å¢ƒ"""
        self.test_symbols = ["EUR_USD"]
        self.initial_capital = 10000
        self.max_trade_amount = 0.1
        self.short_training_steps = 50  # çŸ­æœŸè¨“ç·´ï¼Œå°ˆæ³¨æ–¼æµç¨‹é©—è­‰
        
    def test_imports_and_basic_setup(self):
        """éšæ®µ 1: æ¸¬è©¦æ‰€æœ‰å¿…è¦æ¨¡çµ„çš„å°å…¥"""
        print("\nğŸ”§ éšæ®µ 1: æ¸¬è©¦æ¨¡çµ„å°å…¥...")
        
        try:
            # æ ¸å¿ƒæ¨¡çµ„å°å…¥
            from src.environment.trading_env import UniversalTradingEnvV4
            from src.agent.sac_agent_wrapper import QuantumEnhancedSAC
            from stable_baselines3.common.vec_env import DummyVecEnv
            
            print("âœ… æ ¸å¿ƒæ¨¡çµ„å°å…¥æˆåŠŸ")
            
            # å˜—è©¦å°å…¥å¢å¼·æ¨¡çµ„
            try:
                from src.models.enhanced_transformer import EnhancedTransformer
                print("âœ… Enhanced Transformer å°å…¥æˆåŠŸ")
                self.enhanced_transformer_available = True
            except ImportError as e:
                print(f"âš ï¸  Enhanced Transformer å°å…¥å¤±æ•—: {e}")
                self.enhanced_transformer_available = False
            
            try:
                from src.agent.enhanced_quantum_strategy_layer import EnhancedStrategySuperposition
                print("âœ… é‡å­ç­–ç•¥å±¤å°å…¥æˆåŠŸ")
                self.quantum_strategies_available = True
            except ImportError as e:
                print(f"âš ï¸  é‡å­ç­–ç•¥å±¤å°å…¥å¤±æ•—: {e}")
                self.quantum_strategies_available = False
            
            try:
                from src.environment.progressive_reward_system import ProgressiveLearningSystem
                print("âœ… æ¼¸é€²å¼çå‹µç³»çµ±å°å…¥æˆåŠŸ")
                self.progressive_rewards_available = True
            except ImportError as e:
                print(f"âš ï¸  æ¼¸é€²å¼çå‹µç³»çµ±å°å…¥å¤±æ•—: {e}")
                self.progressive_rewards_available = False
            
        except ImportError as e:
            self.fail(f"æ ¸å¿ƒæ¨¡çµ„å°å…¥å¤±æ•—: {e}")
    
    def test_environment_creation_and_basic_interaction(self):
        """éšæ®µ 2: æ¸¬è©¦ç’°å¢ƒå‰µå»ºå’ŒåŸºæœ¬äº¤äº’"""
        print("\nğŸŒ éšæ®µ 2: æ¸¬è©¦ç’°å¢ƒå‰µå»ºå’ŒåŸºæœ¬äº¤äº’...")
        
        try:
            from src.environment.trading_env import UniversalTradingEnvV4
            from stable_baselines3.common.vec_env import DummyVecEnv
            
            # å‰µå»ºç’°å¢ƒ
            def make_env():
                return UniversalTradingEnvV4(
                    symbols=self.test_symbols,
                    initial_capital=self.initial_capital,
                    max_trade_amount=self.max_trade_amount
                )
            
            env = DummyVecEnv([make_env])
            
            # æ¸¬è©¦ç’°å¢ƒé‡ç½®
            obs = env.reset()
            self.assertIsNotNone(obs)
            self.assertGreater(obs.shape[0], 0)
            print(f"âœ… ç’°å¢ƒé‡ç½®æˆåŠŸï¼Œè§€å¯Ÿç¶­åº¦: {obs.shape}")
            
            # æ¸¬è©¦éš¨æ©Ÿå‹•ä½œ
            action_space = env.action_space
            random_action = [action_space.sample() for _ in range(env.num_envs)]
            
            next_obs, reward, done, info = env.step(random_action)
            
            self.assertIsNotNone(next_obs)
            self.assertIsNotNone(reward)
            self.assertIsInstance(done, (list, np.ndarray))
            print("âœ… ç’°å¢ƒæ­¥é©ŸåŸ·è¡ŒæˆåŠŸ")
            
            # ä¿å­˜ç’°å¢ƒä¾›å¾ŒçºŒæ¸¬è©¦ä½¿ç”¨
            self.test_env = env
            self.initial_obs = obs
            
        except Exception as e:
            self.fail(f"ç’°å¢ƒå‰µå»ºå¤±æ•—: {e}")
    
    def test_agent_creation_and_policy_setup(self):
        """éšæ®µ 3: æ¸¬è©¦æ™ºèƒ½é«”å‰µå»ºå’Œç­–ç•¥è¨­ç½®"""
        print("\nğŸ¤– éšæ®µ 3: æ¸¬è©¦æ™ºèƒ½é«”å‰µå»ºå’Œç­–ç•¥è¨­ç½®...")
        
        try:
            from src.agent.sac_agent_wrapper import QuantumEnhancedSAC
            
            # å‰µå»ºæ™ºèƒ½é«”
            agent = QuantumEnhancedSAC(
                env=self.test_env,
                learning_rate=3e-4,
                batch_size=32,
                buffer_size=1000,
                learning_starts=10,  # å¿«é€Ÿé–‹å§‹å­¸ç¿’
                verbose=1
            )
            
            self.assertIsNotNone(agent)
            self.assertIsNotNone(agent.agent)
            print("âœ… SAC æ™ºèƒ½é«”å‰µå»ºæˆåŠŸ")
            
            # æ¸¬è©¦ç­–ç•¥ç¶²çµ¡
            if hasattr(agent.agent, 'policy'):
                policy = agent.agent.policy
                print(f"âœ… ç­–ç•¥ç¶²çµ¡: {type(policy).__name__}")
                
                # æª¢æŸ¥ç‰¹å¾µæå–å™¨
                if hasattr(policy, 'features_extractor'):
                    features_extractor = policy.features_extractor
                    print(f"âœ… ç‰¹å¾µæå–å™¨: {type(features_extractor).__name__}")
                    
                    # å¦‚æœæ˜¯å¢å¼·çš„ Transformer
                    if 'Transformer' in type(features_extractor).__name__:
                        print("âœ… ä½¿ç”¨å¢å¼·çš„ Transformer ç‰¹å¾µæå–å™¨")
            
            # ä¿å­˜æ™ºèƒ½é«”ä¾›å¾ŒçºŒæ¸¬è©¦ä½¿ç”¨
            self.test_agent = agent
            
        except Exception as e:
            self.fail(f"æ™ºèƒ½é«”å‰µå»ºå¤±æ•—: {e}")
    
    def test_initial_prediction_and_model_parameters(self):
        """éšæ®µ 4: æ¸¬è©¦åˆå§‹é æ¸¬å’Œæ¨¡å‹åƒæ•¸"""
        print("\nğŸ”® éšæ®µ 4: æ¸¬è©¦åˆå§‹é æ¸¬å’Œæ¨¡å‹åƒæ•¸...")
        
        try:
            # æ¸¬è©¦åˆå§‹é æ¸¬
            action, _ = self.test_agent.predict(self.initial_obs, deterministic=True)
            self.assertIsNotNone(action)
            print(f"âœ… åˆå§‹é æ¸¬æˆåŠŸï¼Œå‹•ä½œå½¢ç‹€: {action.shape}")
            
            # è¨˜éŒ„åˆå§‹æ¨¡å‹åƒæ•¸ï¼ˆç”¨æ–¼å¾ŒçºŒæª¢æŸ¥æ¬Šé‡æ›´æ–°ï¼‰
            self.initial_model_params = {}
            
            if hasattr(self.test_agent.agent.policy, 'features_extractor'):
                feature_extractor = self.test_agent.agent.policy.features_extractor
                param_count = 0
                for name, param in feature_extractor.named_parameters():
                    self.initial_model_params[f"features_extractor.{name}"] = param.clone().detach()
                    param_count += param.numel()
                print(f"âœ… ç‰¹å¾µæå–å™¨åƒæ•¸è¨˜éŒ„å®Œæˆï¼Œç¸½åƒæ•¸æ•¸é‡: {param_count:,}")
            
            # è¨˜éŒ„ Actor å’Œ Critic ç¶²çµ¡åƒæ•¸
            if hasattr(self.test_agent.agent.policy, 'actor'):
                actor = self.test_agent.agent.policy.actor
                for name, param in actor.named_parameters():
                    self.initial_model_params[f"actor.{name}"] = param.clone().detach()
                print("âœ… Actor ç¶²çµ¡åƒæ•¸è¨˜éŒ„å®Œæˆ")
            
            if hasattr(self.test_agent.agent.policy, 'critic'):
                critic = self.test_agent.agent.policy.critic
                for name, param in critic.named_parameters():
                    self.initial_model_params[f"critic.{name}"] = param.clone().detach()
                print("âœ… Critic ç¶²çµ¡åƒæ•¸è¨˜éŒ„å®Œæˆ")
            
            print(f"âœ… ç¸½å…±è¨˜éŒ„äº† {len(self.initial_model_params)} å€‹åƒæ•¸å¼µé‡")
            
        except Exception as e:
            self.fail(f"åˆå§‹é æ¸¬æ¸¬è©¦å¤±æ•—: {e}")
    
    def test_short_training_and_gradient_flow(self):
        """éšæ®µ 5: æ¸¬è©¦çŸ­æœŸè¨“ç·´å’Œæ¢¯åº¦æµ"""
        print(f"\nğŸ¯ éšæ®µ 5: æ¸¬è©¦çŸ­æœŸè¨“ç·´å’Œæ¢¯åº¦æµ ({self.short_training_steps} æ­¥)...")
        
        try:
            import time
            
            # è¨˜éŒ„è¨“ç·´é–‹å§‹æ™‚é–“
            start_time = time.time()
            
            # åŸ·è¡ŒçŸ­æœŸè¨“ç·´
            print(f"â³ é–‹å§‹ {self.short_training_steps} æ­¥è¨“ç·´...")
            self.test_agent.train(total_timesteps=self.short_training_steps)
            
            training_duration = time.time() - start_time
            print(f"âœ… è¨“ç·´å®Œæˆï¼Œè€—æ™‚: {training_duration:.2f} ç§’")
            
        except Exception as e:
            print(f"âš ï¸  è¨“ç·´éç¨‹å‡ºç¾éŒ¯èª¤: {e}")
            # ä¸ç›´æ¥å¤±æ•—ï¼Œç¹¼çºŒæª¢æŸ¥å…¶ä»–éƒ¨åˆ†
    
    def test_weight_updates_and_gradient_propagation(self):
        """éšæ®µ 6: æ¸¬è©¦æ¬Šé‡æ›´æ–°å’Œæ¢¯åº¦å‚³æ’­"""
        print("\nğŸ“Š éšæ®µ 6: æ¸¬è©¦æ¬Šé‡æ›´æ–°å’Œæ¢¯åº¦å‚³æ’­...")
        
        try:
            # æª¢æŸ¥æ¨¡å‹åƒæ•¸æ˜¯å¦æ›´æ–°
            weights_changed = {}
            unchanged_params = []
            changed_params = []
            
            current_params = {}
            
            # ç²å–ç•¶å‰åƒæ•¸
            if hasattr(self.test_agent.agent.policy, 'features_extractor'):
                feature_extractor = self.test_agent.agent.policy.features_extractor
                for name, param in feature_extractor.named_parameters():
                    current_params[f"features_extractor.{name}"] = param.clone().detach()
            
            if hasattr(self.test_agent.agent.policy, 'actor'):
                actor = self.test_agent.agent.policy.actor
                for name, param in actor.named_parameters():
                    current_params[f"actor.{name}"] = param.clone().detach()
            
            if hasattr(self.test_agent.agent.policy, 'critic'):
                critic = self.test_agent.agent.policy.critic
                for name, param in critic.named_parameters():
                    current_params[f"critic.{name}"] = param.clone().detach()
            
            # æ¯”è¼ƒåƒæ•¸è®ŠåŒ–
            for param_name in self.initial_model_params:
                if param_name in current_params:
                    initial = self.initial_model_params[param_name]
                    current = current_params[param_name]
                    
                    # æª¢æŸ¥æ˜¯å¦ç›¸ç­‰
                    if torch.equal(initial, current):
                        unchanged_params.append(param_name)
                        weights_changed[param_name] = False
                    else:
                        changed_params.append(param_name)
                        weights_changed[param_name] = True
                        
                        # è¨ˆç®—è®ŠåŒ–å¹…åº¦
                        diff = torch.abs(current - initial).mean().item()
                        print(f"  ğŸ“ˆ {param_name}: å¹³å‡è®ŠåŒ– {diff:.8f}")
            
            print(f"\nğŸ“Š æ¬Šé‡æ›´æ–°çµ±è¨ˆ:")
            print(f"  âœ… å·²æ›´æ–°åƒæ•¸: {len(changed_params)}")
            print(f"  âš ï¸  æœªæ›´æ–°åƒæ•¸: {len(unchanged_params)}")
            
            if len(changed_params) > 0:
                print("âœ… æ¢¯åº¦æµæ­£å¸¸ï¼Œæ¨¡å‹åƒæ•¸æ­£åœ¨æ›´æ–°")
                
                # é¡¯ç¤ºä¸€äº›æ›´æ–°çš„åƒæ•¸
                print("\nğŸ” æ›´æ–°çš„åƒæ•¸ç¤ºä¾‹:")
                for i, param_name in enumerate(changed_params[:5]):  # é¡¯ç¤ºå‰5å€‹
                    print(f"  - {param_name}")
                
            else:
                print("âš ï¸  æ²’æœ‰åƒæ•¸æ›´æ–°ï¼Œå¯èƒ½éœ€è¦æ›´å¤šè¨“ç·´æ­¥é©Ÿæˆ–æª¢æŸ¥å­¸ç¿’ç‡")
            
            if len(unchanged_params) > 0:
                print("\nâš ï¸  æœªæ›´æ–°çš„åƒæ•¸:")
                for param_name in unchanged_params[:5]:  # é¡¯ç¤ºå‰5å€‹
                    print(f"  - {param_name}")
            
            # è‡³å°‘æ‡‰è©²æœ‰ä¸€äº›åƒæ•¸æ›´æ–°
            self.assertGreater(len(changed_params), 0, 
                             "æ²’æœ‰ä»»ä½•æ¨¡å‹åƒæ•¸æ›´æ–°ï¼Œæ¢¯åº¦æµå¯èƒ½æœ‰å•é¡Œ")
            
        except Exception as e:
            self.fail(f"æ¬Šé‡æ›´æ–°æª¢æŸ¥å¤±æ•—: {e}")
    
    def test_post_training_prediction_consistency(self):
        """éšæ®µ 7: æ¸¬è©¦è¨“ç·´å¾Œé æ¸¬ä¸€è‡´æ€§"""
        print("\nğŸ”„ éšæ®µ 7: æ¸¬è©¦è¨“ç·´å¾Œé æ¸¬ä¸€è‡´æ€§...")
        
        try:
            # æ¸¬è©¦è¨“ç·´å¾Œçš„é æ¸¬
            obs = self.test_env.reset()
            action1, _ = self.test_agent.predict(obs, deterministic=True)
            action2, _ = self.test_agent.predict(obs, deterministic=True)
            
            # ç¢ºå®šæ€§é æ¸¬æ‡‰è©²ä¸€è‡´
            np.testing.assert_array_almost_equal(action1, action2, decimal=6)
            print("âœ… è¨“ç·´å¾Œç¢ºå®šæ€§é æ¸¬ä¸€è‡´")
            
            # æ¸¬è©¦éš¨æ©Ÿé æ¸¬
            action3, _ = self.test_agent.predict(obs, deterministic=False)
            action4, _ = self.test_agent.predict(obs, deterministic=False)
            
            # éš¨æ©Ÿé æ¸¬æ‡‰è©²ä¸åŒï¼ˆä½†å½¢ç‹€ç›¸åŒï¼‰
            self.assertEqual(action3.shape, action4.shape)
            print("âœ… éš¨æ©Ÿé æ¸¬å½¢ç‹€æ­£ç¢º")
            
        except Exception as e:
            self.fail(f"é æ¸¬ä¸€è‡´æ€§æ¸¬è©¦å¤±æ•—: {e}")
    
    def test_enhanced_components_integration(self):
        """éšæ®µ 8: æ¸¬è©¦å¢å¼·çµ„ä»¶é›†æˆï¼ˆå¦‚æœå¯ç”¨ï¼‰"""
        print("\nğŸš€ éšæ®µ 8: æ¸¬è©¦å¢å¼·çµ„ä»¶é›†æˆ...")
        
        # æ¸¬è©¦é‡å­ç­–ç•¥å±¤é›†æˆ
        if self.quantum_strategies_available:
            try:
                from src.agent.enhanced_quantum_strategy_layer import EnhancedStrategySuperposition
                from src.agent.strategies import STRATEGY_REGISTRY
                
                # å‰µå»ºæ¸¬è©¦é…ç½®
                strategies_config = {
                    "strategies": [
                        {"name": "MomentumStrategy", "params": {"window": 20}, "input_dim": 64},
                        {"name": "MeanReversionStrategy", "params": {"reversion_window": 15}, "input_dim": 64}
                    ]
                }
                
                superposition = EnhancedStrategySuperposition(
                    overall_config_for_strategies=strategies_config,
                    strategy_registry=STRATEGY_REGISTRY
                )
                
                # æ¸¬è©¦å‰å‘å‚³æ’­
                batch_size = 2
                feature_dim = 64
                test_features = torch.randn(batch_size, feature_dim)
                
                output = superposition(test_features)
                self.assertIsNotNone(output)
                print("âœ… é‡å­ç­–ç•¥å±¤é›†æˆæ¸¬è©¦é€šé")
                
            except Exception as e:
                print(f"âš ï¸  é‡å­ç­–ç•¥å±¤é›†æˆæ¸¬è©¦å¤±æ•—: {e}")
        else:
            print("â­ï¸  è·³éé‡å­ç­–ç•¥å±¤æ¸¬è©¦ï¼ˆæ¨¡çµ„ä¸å¯ç”¨ï¼‰")
        
        # æ¸¬è©¦æ¼¸é€²å¼çå‹µç³»çµ±
        if self.progressive_rewards_available:
            try:
                from src.environment.progressive_reward_system import ProgressiveLearningSystem
                
                reward_system = ProgressiveLearningSystem()
                
                # æ¸¬è©¦åŸºæœ¬çå‹µè¨ˆç®—
                test_profit_loss = 100.0
                test_risk_metrics = {"volatility": 0.02, "drawdown": 0.05}
                
                reward = reward_system.calculate_reward(test_profit_loss, test_risk_metrics)
                self.assertIsInstance(reward, (int, float))
                print("âœ… æ¼¸é€²å¼çå‹µç³»çµ±é›†æˆæ¸¬è©¦é€šé")
                
            except Exception as e:
                print(f"âš ï¸  æ¼¸é€²å¼çå‹µç³»çµ±é›†æˆæ¸¬è©¦å¤±æ•—: {e}")
        else:
            print("â­ï¸  è·³éæ¼¸é€²å¼çå‹µç³»çµ±æ¸¬è©¦ï¼ˆæ¨¡çµ„ä¸å¯ç”¨ï¼‰")
    
    def test_memory_and_resource_usage(self):
        """éšæ®µ 9: æ¸¬è©¦è¨˜æ†¶é«”å’Œè³‡æºä½¿ç”¨"""
        print("\nğŸ’¾ éšæ®µ 9: æ¸¬è©¦è¨˜æ†¶é«”å’Œè³‡æºä½¿ç”¨...")
        
        try:
            import psutil
            import gc
            
            # ç²å–è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
            process = psutil.Process()
            memory_info = process.memory_info()
            memory_mb = memory_info.rss / 1024 / 1024
            
            print(f"ğŸ“Š ç•¶å‰è¨˜æ†¶é«”ä½¿ç”¨: {memory_mb:.1f} MB")
            
            # æª¢æŸ¥æ˜¯å¦æœ‰æ˜é¡¯çš„è¨˜æ†¶é«”æ´©æ¼
            self.assertLess(memory_mb, 2000, "è¨˜æ†¶é«”ä½¿ç”¨éé«˜ï¼Œå¯èƒ½æœ‰è¨˜æ†¶é«”æ´©æ¼")
            
            # æ¸…ç†è¨˜æ†¶é«”
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            print("âœ… è¨˜æ†¶é«”ä½¿ç”¨æ­£å¸¸")
            
        except ImportError:
            print("â­ï¸  è·³éè¨˜æ†¶é«”æª¢æŸ¥ï¼ˆpsutil ä¸å¯ç”¨ï¼‰")
        except Exception as e:
            print(f"âš ï¸  è¨˜æ†¶é«”æª¢æŸ¥å¤±æ•—: {e}")
    
    def test_model_save_and_load(self):
        """éšæ®µ 10: æ¸¬è©¦æ¨¡å‹ä¿å­˜å’ŒåŠ è¼‰"""
        print("\nğŸ’¾ éšæ®µ 10: æ¸¬è©¦æ¨¡å‹ä¿å­˜å’ŒåŠ è¼‰...")
        
        try:
            import tempfile
            import shutil
            
            # å‰µå»ºè‡¨æ™‚ç›®éŒ„
            temp_dir = tempfile.mkdtemp()
            model_path = os.path.join(temp_dir, "test_model")
            
            try:
                # ä¿å­˜æ¨¡å‹
                self.test_agent.save(model_path)
                print("âœ… æ¨¡å‹ä¿å­˜æˆåŠŸ")
                
                # æª¢æŸ¥ä¿å­˜çš„æ–‡ä»¶
                saved_files = os.listdir(temp_dir)
                self.assertGreater(len(saved_files), 0, "æ²’æœ‰æ–‡ä»¶è¢«ä¿å­˜")
                print(f"âœ… ä¿å­˜äº† {len(saved_files)} å€‹æ–‡ä»¶")
                
                # å‰µå»ºæ–°çš„æ™ºèƒ½é«”ä¸¦åŠ è¼‰æ¨¡å‹
                from src.agent.sac_agent_wrapper import QuantumEnhancedSAC
                
                new_agent = QuantumEnhancedSAC(
                    env=self.test_env,
                    learning_rate=3e-4,
                    batch_size=32,
                    buffer_size=1000
                )
                
                new_agent.load(model_path, env=self.test_env)
                print("âœ… æ¨¡å‹åŠ è¼‰æˆåŠŸ")
                
                # æ¸¬è©¦åŠ è¼‰å¾Œçš„é æ¸¬
                obs = self.test_env.reset()
                action1, _ = self.test_agent.predict(obs, deterministic=True)
                action2, _ = new_agent.predict(obs, deterministic=True)
                
                # é æ¸¬æ‡‰è©²ç›¸åŒ
                np.testing.assert_array_almost_equal(action1, action2, decimal=5)
                print("âœ… åŠ è¼‰å¾Œé æ¸¬ä¸€è‡´")
                
            finally:
                # æ¸…ç†è‡¨æ™‚ç›®éŒ„
                shutil.rmtree(temp_dir)
                
        except Exception as e:
            print(f"âš ï¸  æ¨¡å‹ä¿å­˜/åŠ è¼‰æ¸¬è©¦å¤±æ•—: {e}")
    
    def tearDown(self):
        """æ¸…ç†æ¸¬è©¦ç’°å¢ƒ"""
        # æ¸…ç†ç’°å¢ƒ
        if hasattr(self, 'test_env'):
            self.test_env.close()
        
        # æ¸…ç† GPU è¨˜æ†¶é«”
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

if __name__ == '__main__':
    # é…ç½®è©³ç´°çš„æ¸¬è©¦é‹è¡Œ
    unittest.main(verbosity=2, buffer=True)
